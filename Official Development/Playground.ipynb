{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ejose\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\arrays\\masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "# Import Libraries\n",
    "import pandas as pd\n",
    "import lightgbm as lgbm\n",
    "import catboost as catb\n",
    "from joblib import load\n",
    "\n",
    "import sklearn.metrics as metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ejose\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:376: InconsistentVersionWarning: Trying to unpickle estimator LabelEncoder from version 1.2.1 when using version 1.4.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Load Models\n",
    "default_tb_lgbm = load('./GBDT_Training/Outputs/Results/Demo/LGBM/Train (Default)/DEMO_LGBM_TB.model') # <== Point these to the respective .model files\n",
    "default_ib_lgbm = load('./GBDT_Training/Outputs/Results/Demo/LGBM/Train (Default)/DEMO_LGBM_IB.model')\n",
    "tuned_tb_lgbm = load('./GBDT_Training/Outputs/Results/Demo/LGBM/Train (Tuned)/TUNED_DEMO_LGBM_TB.model')\n",
    "tuned_ib_lgbm = load('./GBDT_Training/Outputs/Results/Demo/LGBM/Train (Tuned)/TUNED_DEMO_LGBM_IB.model')\n",
    "\n",
    "default_tb_catb = catb.CatBoostClassifier()\n",
    "default_ib_catb = catb.CatBoostClassifier()\n",
    "tuned_tb_catb = catb.CatBoostClassifier()\n",
    "tuned_ib_catb = catb.CatBoostClassifier()\n",
    "default_tb_catb = default_tb_catb.load_model(\"./GBDT_Training/Outputs/Results/Demo/CATB/Train (Default)//DEMO_CATB_TB.model\", format='json') # <== Point these to the respective .model files\n",
    "default_ib_catb = default_ib_catb.load_model(\"./GBDT_Training/Outputs/Results/Demo/CATB/Train (Default)/DEMO_CATB_IB.model\", format='json')\n",
    "tuned_tb_catb = tuned_tb_catb.load_model(\"./GBDT_Training/Outputs/Results/Demo/CATB/Train (Tuned)/TUNED_DEMO_CATB_TB.model\", format='json')\n",
    "tuned_ib_catb = tuned_ib_catb.load_model(\"./GBDT_Training/Outputs/Results/Demo/CATB/Train (Tuned)/TUNED_DEMO_CATB_IB.model\", format='json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Test/Holdout Datasets\n",
    "\n",
    "DF_LGBM_TB = pd.read_csv('./Dataset/TB/LGBM_TB_Test.csv', low_memory=False) #<== Point these to the proper Test/Holdout datasets.\n",
    "DF_LGBM_IB = pd.read_csv('./Dataset/IB/LGBM_IB_Test.csv', low_memory=False)\n",
    "\n",
    "DF_CATB_TB = pd.read_csv('./Dataset/TB/CATB_TB_Test.csv', low_memory=False) #<== Point these to the proper Test/Holdout datasets.\n",
    "DF_CATB_IB = pd.read_csv('./Dataset/IB/CATB_IB_Test.csv', low_memory=False)\n",
    "\n",
    "DF_CATB_TB = DF_CATB_TB.fillna(\"NaN\")\n",
    "DF_CATB_IB = DF_CATB_IB.fillna(\"NaN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default TB LGBM\n",
      "[LightGBM] [Warning] Unknown parameter: categorical_data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9194    0.5481    0.6867       104\n",
      "           1     0.9891    0.9988    0.9940      4284\n",
      "\n",
      "    accuracy                         0.9881      4388\n",
      "   macro avg     0.9542    0.7735    0.8404      4388\n",
      "weighted avg     0.9875    0.9881    0.9867      4388\n",
      "\n",
      "Tuned TB LGBM\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9016    0.5288    0.6667       104\n",
      "           1     0.9887    0.9986    0.9936      4284\n",
      "\n",
      "    accuracy                         0.9875      4388\n",
      "   macro avg     0.9452    0.7637    0.8301      4388\n",
      "weighted avg     0.9866    0.9875    0.9859      4388\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Default TB LGBM\")\n",
    "print(metric.classification_report(DF_LGBM_TB['malware'], default_tb_lgbm.predict(DF_LGBM_TB.iloc[:,1:101]),digits=4))\n",
    "\n",
    "print(\"Tuned TB LGBM\")\n",
    "print(metric.classification_report(DF_LGBM_TB['malware'], tuned_tb_lgbm.predict(DF_LGBM_TB.iloc[:,1:101]),digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default IB LGBM\n",
      "[LightGBM] [Warning] Unknown parameter: categorical_data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8904    0.6250    0.7345       104\n",
      "           1     0.9910    0.9981    0.9945      4284\n",
      "\n",
      "    accuracy                         0.9893      4388\n",
      "   macro avg     0.9407    0.8116    0.8645      4388\n",
      "weighted avg     0.9886    0.9893    0.9884      4388\n",
      "\n",
      "Tuned IB LGBM\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8182    0.5192    0.6353       104\n",
      "           1     0.9884    0.9972    0.9928      4284\n",
      "\n",
      "    accuracy                         0.9859      4388\n",
      "   macro avg     0.9033    0.7582    0.8140      4388\n",
      "weighted avg     0.9844    0.9859    0.9843      4388\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Default IB LGBM\")\n",
    "print(metric.classification_report(DF_LGBM_IB['malware'], default_ib_lgbm.predict(DF_LGBM_IB.iloc[:,1:101]),digits=4))\n",
    "print(\"Tuned IB LGBM\")\n",
    "print(metric.classification_report(DF_LGBM_IB['malware'], tuned_ib_lgbm.predict(DF_LGBM_IB.iloc[:,1:101]),digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default TB CATB\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9524    0.5769    0.7186       104\n",
      "           1     0.9898    0.9993    0.9945      4284\n",
      "\n",
      "    accuracy                         0.9893      4388\n",
      "   macro avg     0.9711    0.7881    0.8566      4388\n",
      "weighted avg     0.9889    0.9893    0.9880      4388\n",
      "\n",
      "Tuned TB CATB\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9394    0.5962    0.7294       104\n",
      "           1     0.9903    0.9991    0.9947      4284\n",
      "\n",
      "    accuracy                         0.9895      4388\n",
      "   macro avg     0.9648    0.7976    0.8620      4388\n",
      "weighted avg     0.9891    0.9895    0.9884      4388\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Default TB CATB\")\n",
    "print(metric.classification_report(DF_CATB_TB['malware'], default_tb_catb.predict(DF_CATB_TB.iloc[:,1:101]),digits=4))\n",
    "print(\"Tuned TB CATB\")\n",
    "print(metric.classification_report(DF_CATB_TB['malware'], tuned_tb_catb.predict(DF_CATB_TB.iloc[:,1:101]),digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default IB CATB\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9189    0.6538    0.7640       104\n",
      "           1     0.9917    0.9986    0.9951      4284\n",
      "\n",
      "    accuracy                         0.9904      4388\n",
      "   macro avg     0.9553    0.8262    0.8796      4388\n",
      "weighted avg     0.9899    0.9904    0.9896      4388\n",
      "\n",
      "Tuned IB CATB\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9242    0.5865    0.7176       104\n",
      "           1     0.9901    0.9988    0.9944      4284\n",
      "\n",
      "    accuracy                         0.9891      4388\n",
      "   macro avg     0.9571    0.7927    0.8560      4388\n",
      "weighted avg     0.9885    0.9891    0.9879      4388\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Default IB CATB\")\n",
    "print(metric.classification_report(DF_CATB_IB['malware'], default_ib_catb.predict(DF_CATB_IB.iloc[:,1:101]),digits=4))\n",
    "print(\"Tuned IB CATB\")\n",
    "print(metric.classification_report(DF_CATB_IB['malware'], tuned_ib_catb.predict(DF_CATB_IB.iloc[:,1:101]),digits=4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
