{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-10T13:34:16.222087Z",
     "iopub.status.busy": "2024-04-10T13:34:16.221086Z",
     "iopub.status.idle": "2024-04-10T13:34:20.795381Z",
     "shell.execute_reply": "2024-04-10T13:34:20.795381Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import lightgbm as lgbm\n",
    "import catboost as catb\n",
    "import sklearn.svm as svc\n",
    "import sklearn.neural_network as mlpc\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "df = pd.read_csv('./Dataset/oliveira_labelled.csv')\n",
    "\n",
    "API_LIST = \"./Dataset/api_calls.txt\"\n",
    "DELIMITER = \"NaN\"\n",
    "API_FILE = open(API_LIST,\"r\")\n",
    "APIS = API_FILE.readline().split(',')\n",
    "APIS.append(DELIMITER) #serves as a label for NaN values for Instance-based datasets\n",
    "API_FILE.close()\n",
    "\n",
    "#Inverse Label Encoding\n",
    "def inverse_label(item:str):\n",
    "    global APIS\n",
    "    return item.map(lambda x: APIS[int(x)])\n",
    "\n",
    "def list_to_str(ls:list):\n",
    "    '''Convert list to a stringified version (comma delimited).'''\n",
    "    output = \"\"\n",
    "    for l in ls:\n",
    "        output += str(l) + \",\"\n",
    "    return output[0:len(output)-1]\n",
    "\n",
    "def inject_patterns(inner_df:pd.DataFrame):\n",
    "    '''Injects the API call patterns of each sample as its last column'''\n",
    "    patterns = []\n",
    "    print(\"Injecting API patterns...\")\n",
    "    for row in range(inner_df.shape[0]):\n",
    "        patterns.append(list_to_str(inner_df.iloc[row,1:101].transpose().to_list()))\n",
    "    inner_df['pattern'] = patterns\n",
    "    return inner_df # DBSCAN requires only the numeric label encoded version of the API Calls\n",
    "\n",
    "def ib_convert(input_df:pd.DataFrame):\n",
    "    print(\"Transposing IB...\")\n",
    "    input_df.transpose()\n",
    "    print(\"IB Transposed!\")\n",
    "    print(\"Removing duplicates...\")\n",
    "    print(\"Row:\", end=\" \")\n",
    "    for r in range(input_df.shape[0]):\n",
    "        row = input_df.iloc[r, 1:101].drop_duplicates(keep='first', inplace=False).to_list()\n",
    "        input_df.iloc[r, 1:101] = row + ([307]*(100-len(row)))\n",
    "        if r % 100 == 0:\n",
    "            print(r, end=\" \")\n",
    "    print(\"\\nDuplicates removed!\")\n",
    "    print(\"Retransposing IB (revert)...\")\n",
    "    input_df.transpose()\n",
    "    print(\"IB Retransposed!\")\n",
    "    return input_df\n",
    "\n",
    "# Remove falsely labelled malicious samples\n",
    "df = df[df['type'] != '_']\n",
    "\n",
    "# Remove specific malware types\n",
    "# removables = ['ransomware', 'miner', 'virus', 'spyware', 'hacktool', 'dropper', 'worm']\n",
    "# for r in removables:\n",
    "#     df = df[df['type'] != r]\n",
    "\n",
    "#Remove type column\n",
    "type_col = df.pop('type')\n",
    "\n",
    "#Removing hash column\n",
    "hash_col = df.pop('hash')\n",
    "\n",
    "#Re-arranging column positions\n",
    "label_col = df.pop('malware')\n",
    "df = pd.concat([label_col, df], axis=1)\n",
    "df = pd.concat([df, hash_col], axis=1) # <=== This will be retained for the benefit of model evaluation.\n",
    "df = pd.concat([df, type_col], axis=1) # <=== This will be retained for the benefit of model evaluation.\n",
    "\n",
    "#df.iloc[:, 1:101] = df.iloc[:, 1:101].apply(inverse_label, axis=1, result_type='reduce')\n",
    "#df = inject_patterns(df)\n",
    "\n",
    "mal_df = df[df['malware'] == 1]\n",
    "ben_df = df[df['malware'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-10T13:34:20.800388Z",
     "iopub.status.busy": "2024-04-10T13:34:20.800388Z",
     "iopub.status.idle": "2024-04-10T13:34:20.834885Z",
     "shell.execute_reply": "2024-04-10T13:34:20.834885Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Benign for Training: 1001\n",
      "Bening for Test:  76\n"
     ]
    }
   ],
   "source": [
    "X = ben_df.iloc[:,1:] #Features\n",
    "y = ben_df.iloc[:,0] #Labels\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(X, y, test_size=0.07, random_state=1, shuffle=True)\n",
    "\n",
    "ben_train = pd.concat([train_labels,train_features], axis=1)\n",
    "ben_test = pd.concat([test_labels,test_features], axis=1)\n",
    "\n",
    "print(\"Benign for Training:\", ben_train['type'].value_counts().sum())\n",
    "print(\"Bening for Test: \", ben_test['type'].value_counts().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-10T13:34:20.902895Z",
     "iopub.status.busy": "2024-04-10T13:34:20.901897Z",
     "iopub.status.idle": "2024-04-10T13:34:21.084094Z",
     "shell.execute_reply": "2024-04-10T13:34:21.083083Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Malicious for Training: 2008\n",
      "Malicious for Testing: 38151\n"
     ]
    }
   ],
   "source": [
    "X = mal_df.iloc[:,1:] #Features\n",
    "y = mal_df.iloc[:,0] #Labels\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(X, y, test_size=0.05, random_state=1, shuffle=True)\n",
    "\n",
    "mal_test = pd.concat([train_labels,train_features], axis=1)\n",
    "mal_train = pd.concat([test_labels,test_features], axis=1)\n",
    "\n",
    "print(\"Malicious for Training:\", mal_train['type'].value_counts().sum())\n",
    "print(\"Malicious for Testing:\", mal_test['type'].value_counts().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## mal_test + ben_test\n",
    "\n",
    "To not undergo SMOTETonek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-10T13:34:21.088095Z",
     "iopub.status.busy": "2024-04-10T13:34:21.088095Z",
     "iopub.status.idle": "2024-04-10T13:34:21.180302Z",
     "shell.execute_reply": "2024-04-10T13:34:21.180302Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(38227, 103)\n",
      "malware\n",
      "1    38151\n",
      "0       76\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>malware</th>\n",
       "      <th>t_0</th>\n",
       "      <th>t_1</th>\n",
       "      <th>t_2</th>\n",
       "      <th>t_3</th>\n",
       "      <th>t_4</th>\n",
       "      <th>t_5</th>\n",
       "      <th>t_6</th>\n",
       "      <th>t_7</th>\n",
       "      <th>t_8</th>\n",
       "      <th>...</th>\n",
       "      <th>t_92</th>\n",
       "      <th>t_93</th>\n",
       "      <th>t_94</th>\n",
       "      <th>t_95</th>\n",
       "      <th>t_96</th>\n",
       "      <th>t_97</th>\n",
       "      <th>t_98</th>\n",
       "      <th>t_99</th>\n",
       "      <th>hash</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>82</td>\n",
       "      <td>240</td>\n",
       "      <td>117</td>\n",
       "      <td>240</td>\n",
       "      <td>117</td>\n",
       "      <td>240</td>\n",
       "      <td>117</td>\n",
       "      <td>240</td>\n",
       "      <td>117</td>\n",
       "      <td>...</td>\n",
       "      <td>260</td>\n",
       "      <td>141</td>\n",
       "      <td>260</td>\n",
       "      <td>141</td>\n",
       "      <td>260</td>\n",
       "      <td>141</td>\n",
       "      <td>260</td>\n",
       "      <td>141</td>\n",
       "      <td>0e7d7102340ce1be5da358fe7b5e26bc</td>\n",
       "      <td>trojan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>112</td>\n",
       "      <td>274</td>\n",
       "      <td>158</td>\n",
       "      <td>215</td>\n",
       "      <td>274</td>\n",
       "      <td>158</td>\n",
       "      <td>215</td>\n",
       "      <td>298</td>\n",
       "      <td>76</td>\n",
       "      <td>...</td>\n",
       "      <td>297</td>\n",
       "      <td>135</td>\n",
       "      <td>171</td>\n",
       "      <td>215</td>\n",
       "      <td>35</td>\n",
       "      <td>208</td>\n",
       "      <td>56</td>\n",
       "      <td>71</td>\n",
       "      <td>a7ec21a4aa58d63df76b6038266c4c45</td>\n",
       "      <td>trojan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>286</td>\n",
       "      <td>110</td>\n",
       "      <td>172</td>\n",
       "      <td>240</td>\n",
       "      <td>117</td>\n",
       "      <td>240</td>\n",
       "      <td>117</td>\n",
       "      <td>240</td>\n",
       "      <td>117</td>\n",
       "      <td>...</td>\n",
       "      <td>65</td>\n",
       "      <td>86</td>\n",
       "      <td>99</td>\n",
       "      <td>71</td>\n",
       "      <td>215</td>\n",
       "      <td>240</td>\n",
       "      <td>117</td>\n",
       "      <td>240</td>\n",
       "      <td>0a3ad6a2dba1b20f48bf99fa52d8e70e</td>\n",
       "      <td>dropper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>82</td>\n",
       "      <td>198</td>\n",
       "      <td>86</td>\n",
       "      <td>82</td>\n",
       "      <td>274</td>\n",
       "      <td>37</td>\n",
       "      <td>240</td>\n",
       "      <td>117</td>\n",
       "      <td>260</td>\n",
       "      <td>...</td>\n",
       "      <td>260</td>\n",
       "      <td>141</td>\n",
       "      <td>65</td>\n",
       "      <td>257</td>\n",
       "      <td>215</td>\n",
       "      <td>260</td>\n",
       "      <td>141</td>\n",
       "      <td>65</td>\n",
       "      <td>dd583b879899de566de7c6062be60369</td>\n",
       "      <td>trojan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>112</td>\n",
       "      <td>274</td>\n",
       "      <td>158</td>\n",
       "      <td>215</td>\n",
       "      <td>274</td>\n",
       "      <td>158</td>\n",
       "      <td>215</td>\n",
       "      <td>298</td>\n",
       "      <td>76</td>\n",
       "      <td>...</td>\n",
       "      <td>297</td>\n",
       "      <td>135</td>\n",
       "      <td>171</td>\n",
       "      <td>215</td>\n",
       "      <td>35</td>\n",
       "      <td>208</td>\n",
       "      <td>56</td>\n",
       "      <td>71</td>\n",
       "      <td>a49cc0b880f2dd6226164a00746549c0</td>\n",
       "      <td>trojan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 103 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   malware  t_0  t_1  t_2  t_3  t_4  t_5  t_6  t_7  t_8  ...  t_92  t_93  \\\n",
       "0        1   82  240  117  240  117  240  117  240  117  ...   260   141   \n",
       "1        1  112  274  158  215  274  158  215  298   76  ...   297   135   \n",
       "2        1  286  110  172  240  117  240  117  240  117  ...    65    86   \n",
       "3        1   82  198   86   82  274   37  240  117  260  ...   260   141   \n",
       "4        1  112  274  158  215  274  158  215  298   76  ...   297   135   \n",
       "\n",
       "   t_94  t_95  t_96  t_97  t_98  t_99                              hash  \\\n",
       "0   260   141   260   141   260   141  0e7d7102340ce1be5da358fe7b5e26bc   \n",
       "1   171   215    35   208    56    71  a7ec21a4aa58d63df76b6038266c4c45   \n",
       "2    99    71   215   240   117   240  0a3ad6a2dba1b20f48bf99fa52d8e70e   \n",
       "3    65   257   215   260   141    65  dd583b879899de566de7c6062be60369   \n",
       "4   171   215    35   208    56    71  a49cc0b880f2dd6226164a00746549c0   \n",
       "\n",
       "      type  \n",
       "0   trojan  \n",
       "1   trojan  \n",
       "2  dropper  \n",
       "3   trojan  \n",
       "4   trojan  \n",
       "\n",
       "[5 rows x 103 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>malware</th>\n",
       "      <th>t_0</th>\n",
       "      <th>t_1</th>\n",
       "      <th>t_2</th>\n",
       "      <th>t_3</th>\n",
       "      <th>t_4</th>\n",
       "      <th>t_5</th>\n",
       "      <th>t_6</th>\n",
       "      <th>t_7</th>\n",
       "      <th>t_8</th>\n",
       "      <th>...</th>\n",
       "      <th>t_92</th>\n",
       "      <th>t_93</th>\n",
       "      <th>t_94</th>\n",
       "      <th>t_95</th>\n",
       "      <th>t_96</th>\n",
       "      <th>t_97</th>\n",
       "      <th>t_98</th>\n",
       "      <th>t_99</th>\n",
       "      <th>hash</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>38151</th>\n",
       "      <td>0</td>\n",
       "      <td>82</td>\n",
       "      <td>16</td>\n",
       "      <td>208</td>\n",
       "      <td>240</td>\n",
       "      <td>117</td>\n",
       "      <td>215</td>\n",
       "      <td>274</td>\n",
       "      <td>158</td>\n",
       "      <td>215</td>\n",
       "      <td>...</td>\n",
       "      <td>172</td>\n",
       "      <td>117</td>\n",
       "      <td>172</td>\n",
       "      <td>117</td>\n",
       "      <td>172</td>\n",
       "      <td>117</td>\n",
       "      <td>172</td>\n",
       "      <td>117</td>\n",
       "      <td>59147b8b8abf9768ca96badfd91d7bb9</td>\n",
       "      <td>benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38152</th>\n",
       "      <td>0</td>\n",
       "      <td>240</td>\n",
       "      <td>117</td>\n",
       "      <td>240</td>\n",
       "      <td>117</td>\n",
       "      <td>240</td>\n",
       "      <td>117</td>\n",
       "      <td>240</td>\n",
       "      <td>117</td>\n",
       "      <td>240</td>\n",
       "      <td>...</td>\n",
       "      <td>117</td>\n",
       "      <td>35</td>\n",
       "      <td>60</td>\n",
       "      <td>81</td>\n",
       "      <td>208</td>\n",
       "      <td>60</td>\n",
       "      <td>81</td>\n",
       "      <td>60</td>\n",
       "      <td>483b022e6f2805d0cdf4e1db7d1237af</td>\n",
       "      <td>benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38153</th>\n",
       "      <td>0</td>\n",
       "      <td>240</td>\n",
       "      <td>117</td>\n",
       "      <td>240</td>\n",
       "      <td>117</td>\n",
       "      <td>240</td>\n",
       "      <td>117</td>\n",
       "      <td>240</td>\n",
       "      <td>117</td>\n",
       "      <td>240</td>\n",
       "      <td>...</td>\n",
       "      <td>172</td>\n",
       "      <td>117</td>\n",
       "      <td>240</td>\n",
       "      <td>117</td>\n",
       "      <td>172</td>\n",
       "      <td>117</td>\n",
       "      <td>29</td>\n",
       "      <td>25</td>\n",
       "      <td>76457240c1640a0812a3ef57159708b4</td>\n",
       "      <td>benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38154</th>\n",
       "      <td>0</td>\n",
       "      <td>286</td>\n",
       "      <td>110</td>\n",
       "      <td>172</td>\n",
       "      <td>240</td>\n",
       "      <td>117</td>\n",
       "      <td>240</td>\n",
       "      <td>117</td>\n",
       "      <td>240</td>\n",
       "      <td>117</td>\n",
       "      <td>...</td>\n",
       "      <td>114</td>\n",
       "      <td>215</td>\n",
       "      <td>117</td>\n",
       "      <td>71</td>\n",
       "      <td>25</td>\n",
       "      <td>71</td>\n",
       "      <td>275</td>\n",
       "      <td>260</td>\n",
       "      <td>25a904a73a9c6548c39351f3bbfac641</td>\n",
       "      <td>benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38155</th>\n",
       "      <td>0</td>\n",
       "      <td>82</td>\n",
       "      <td>16</td>\n",
       "      <td>35</td>\n",
       "      <td>240</td>\n",
       "      <td>117</td>\n",
       "      <td>86</td>\n",
       "      <td>208</td>\n",
       "      <td>86</td>\n",
       "      <td>31</td>\n",
       "      <td>...</td>\n",
       "      <td>25</td>\n",
       "      <td>60</td>\n",
       "      <td>81</td>\n",
       "      <td>25</td>\n",
       "      <td>60</td>\n",
       "      <td>81</td>\n",
       "      <td>25</td>\n",
       "      <td>60</td>\n",
       "      <td>39dfc1401b7db273933b5fb08e8394f8</td>\n",
       "      <td>benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38222</th>\n",
       "      <td>0</td>\n",
       "      <td>82</td>\n",
       "      <td>16</td>\n",
       "      <td>215</td>\n",
       "      <td>274</td>\n",
       "      <td>158</td>\n",
       "      <td>215</td>\n",
       "      <td>274</td>\n",
       "      <td>158</td>\n",
       "      <td>215</td>\n",
       "      <td>...</td>\n",
       "      <td>198</td>\n",
       "      <td>172</td>\n",
       "      <td>117</td>\n",
       "      <td>260</td>\n",
       "      <td>275</td>\n",
       "      <td>112</td>\n",
       "      <td>71</td>\n",
       "      <td>25</td>\n",
       "      <td>1cad25b4e90a2648fdd25f4f00be3c37</td>\n",
       "      <td>benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38223</th>\n",
       "      <td>0</td>\n",
       "      <td>82</td>\n",
       "      <td>16</td>\n",
       "      <td>82</td>\n",
       "      <td>103</td>\n",
       "      <td>297</td>\n",
       "      <td>286</td>\n",
       "      <td>194</td>\n",
       "      <td>286</td>\n",
       "      <td>85</td>\n",
       "      <td>...</td>\n",
       "      <td>123</td>\n",
       "      <td>208</td>\n",
       "      <td>35</td>\n",
       "      <td>123</td>\n",
       "      <td>112</td>\n",
       "      <td>123</td>\n",
       "      <td>65</td>\n",
       "      <td>172</td>\n",
       "      <td>0b2ec965cee44e5bf3030bd1a61214f8</td>\n",
       "      <td>benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38224</th>\n",
       "      <td>0</td>\n",
       "      <td>286</td>\n",
       "      <td>110</td>\n",
       "      <td>172</td>\n",
       "      <td>240</td>\n",
       "      <td>117</td>\n",
       "      <td>240</td>\n",
       "      <td>117</td>\n",
       "      <td>240</td>\n",
       "      <td>117</td>\n",
       "      <td>...</td>\n",
       "      <td>114</td>\n",
       "      <td>215</td>\n",
       "      <td>117</td>\n",
       "      <td>261</td>\n",
       "      <td>106</td>\n",
       "      <td>144</td>\n",
       "      <td>297</td>\n",
       "      <td>117</td>\n",
       "      <td>139ef237f3b7dced11e58252a96f64a7</td>\n",
       "      <td>benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38225</th>\n",
       "      <td>0</td>\n",
       "      <td>117</td>\n",
       "      <td>172</td>\n",
       "      <td>117</td>\n",
       "      <td>228</td>\n",
       "      <td>172</td>\n",
       "      <td>117</td>\n",
       "      <td>172</td>\n",
       "      <td>117</td>\n",
       "      <td>172</td>\n",
       "      <td>...</td>\n",
       "      <td>274</td>\n",
       "      <td>158</td>\n",
       "      <td>215</td>\n",
       "      <td>240</td>\n",
       "      <td>117</td>\n",
       "      <td>50</td>\n",
       "      <td>172</td>\n",
       "      <td>117</td>\n",
       "      <td>349aae8db20b24d14a90038d5c4c5549</td>\n",
       "      <td>benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38226</th>\n",
       "      <td>0</td>\n",
       "      <td>82</td>\n",
       "      <td>240</td>\n",
       "      <td>117</td>\n",
       "      <td>240</td>\n",
       "      <td>117</td>\n",
       "      <td>240</td>\n",
       "      <td>117</td>\n",
       "      <td>240</td>\n",
       "      <td>117</td>\n",
       "      <td>...</td>\n",
       "      <td>65</td>\n",
       "      <td>260</td>\n",
       "      <td>141</td>\n",
       "      <td>65</td>\n",
       "      <td>112</td>\n",
       "      <td>113</td>\n",
       "      <td>65</td>\n",
       "      <td>289</td>\n",
       "      <td>bdaaac3fa3f6796825a51ef1c0e5b3fd</td>\n",
       "      <td>benign</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76 rows × 103 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       malware  t_0  t_1  t_2  t_3  t_4  t_5  t_6  t_7  t_8  ...  t_92  t_93  \\\n",
       "38151        0   82   16  208  240  117  215  274  158  215  ...   172   117   \n",
       "38152        0  240  117  240  117  240  117  240  117  240  ...   117    35   \n",
       "38153        0  240  117  240  117  240  117  240  117  240  ...   172   117   \n",
       "38154        0  286  110  172  240  117  240  117  240  117  ...   114   215   \n",
       "38155        0   82   16   35  240  117   86  208   86   31  ...    25    60   \n",
       "...        ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   ...   ...   \n",
       "38222        0   82   16  215  274  158  215  274  158  215  ...   198   172   \n",
       "38223        0   82   16   82  103  297  286  194  286   85  ...   123   208   \n",
       "38224        0  286  110  172  240  117  240  117  240  117  ...   114   215   \n",
       "38225        0  117  172  117  228  172  117  172  117  172  ...   274   158   \n",
       "38226        0   82  240  117  240  117  240  117  240  117  ...    65   260   \n",
       "\n",
       "       t_94  t_95  t_96  t_97  t_98  t_99                              hash  \\\n",
       "38151   172   117   172   117   172   117  59147b8b8abf9768ca96badfd91d7bb9   \n",
       "38152    60    81   208    60    81    60  483b022e6f2805d0cdf4e1db7d1237af   \n",
       "38153   240   117   172   117    29    25  76457240c1640a0812a3ef57159708b4   \n",
       "38154   117    71    25    71   275   260  25a904a73a9c6548c39351f3bbfac641   \n",
       "38155    81    25    60    81    25    60  39dfc1401b7db273933b5fb08e8394f8   \n",
       "...     ...   ...   ...   ...   ...   ...                               ...   \n",
       "38222   117   260   275   112    71    25  1cad25b4e90a2648fdd25f4f00be3c37   \n",
       "38223    35   123   112   123    65   172  0b2ec965cee44e5bf3030bd1a61214f8   \n",
       "38224   117   261   106   144   297   117  139ef237f3b7dced11e58252a96f64a7   \n",
       "38225   215   240   117    50   172   117  349aae8db20b24d14a90038d5c4c5549   \n",
       "38226   141    65   112   113    65   289  bdaaac3fa3f6796825a51ef1c0e5b3fd   \n",
       "\n",
       "         type  \n",
       "38151  benign  \n",
       "38152  benign  \n",
       "38153  benign  \n",
       "38154  benign  \n",
       "38155  benign  \n",
       "...       ...  \n",
       "38222  benign  \n",
       "38223  benign  \n",
       "38224  benign  \n",
       "38225  benign  \n",
       "38226  benign  \n",
       "\n",
       "[76 rows x 103 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_tb = pd.concat([mal_test, ben_test], axis=0, ignore_index=True)\n",
    "print(test_tb.shape)\n",
    "print(test_tb['malware'].value_counts())\n",
    "display(test_tb.head())\n",
    "display(test_tb[test_tb['malware']==0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## mal_train + ben_train\n",
    "\n",
    "To undergo *SMOTETomek*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-10T13:34:21.185315Z",
     "iopub.status.busy": "2024-04-10T13:34:21.184313Z",
     "iopub.status.idle": "2024-04-10T13:34:21.199605Z",
     "shell.execute_reply": "2024-04-10T13:34:21.199605Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3009, 103)\n",
      "malware\n",
      "1    2008\n",
      "0    1001\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "train_tb = pd.concat([mal_train, ben_train], axis=0, ignore_index=True)\n",
    "print(train_tb.shape)\n",
    "print(train_tb['malware'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-10T13:34:21.204615Z",
     "iopub.status.busy": "2024-04-10T13:34:21.203615Z",
     "iopub.status.idle": "2024-04-10T13:34:21.794799Z",
     "shell.execute_reply": "2024-04-10T13:34:21.794799Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2988, 101)\n",
      "malware\n",
      "1    1996\n",
      "0     992\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>malware</th>\n",
       "      <th>t_0</th>\n",
       "      <th>t_1</th>\n",
       "      <th>t_2</th>\n",
       "      <th>t_3</th>\n",
       "      <th>t_4</th>\n",
       "      <th>t_5</th>\n",
       "      <th>t_6</th>\n",
       "      <th>t_7</th>\n",
       "      <th>t_8</th>\n",
       "      <th>...</th>\n",
       "      <th>t_90</th>\n",
       "      <th>t_91</th>\n",
       "      <th>t_92</th>\n",
       "      <th>t_93</th>\n",
       "      <th>t_94</th>\n",
       "      <th>t_95</th>\n",
       "      <th>t_96</th>\n",
       "      <th>t_97</th>\n",
       "      <th>t_98</th>\n",
       "      <th>t_99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>82</td>\n",
       "      <td>240</td>\n",
       "      <td>117</td>\n",
       "      <td>240</td>\n",
       "      <td>117</td>\n",
       "      <td>240</td>\n",
       "      <td>117</td>\n",
       "      <td>240</td>\n",
       "      <td>117</td>\n",
       "      <td>...</td>\n",
       "      <td>172</td>\n",
       "      <td>117</td>\n",
       "      <td>93</td>\n",
       "      <td>208</td>\n",
       "      <td>16</td>\n",
       "      <td>31</td>\n",
       "      <td>215</td>\n",
       "      <td>108</td>\n",
       "      <td>215</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>286</td>\n",
       "      <td>110</td>\n",
       "      <td>172</td>\n",
       "      <td>240</td>\n",
       "      <td>117</td>\n",
       "      <td>240</td>\n",
       "      <td>117</td>\n",
       "      <td>240</td>\n",
       "      <td>117</td>\n",
       "      <td>...</td>\n",
       "      <td>65</td>\n",
       "      <td>202</td>\n",
       "      <td>65</td>\n",
       "      <td>117</td>\n",
       "      <td>260</td>\n",
       "      <td>297</td>\n",
       "      <td>215</td>\n",
       "      <td>114</td>\n",
       "      <td>215</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>82</td>\n",
       "      <td>172</td>\n",
       "      <td>117</td>\n",
       "      <td>16</td>\n",
       "      <td>29</td>\n",
       "      <td>208</td>\n",
       "      <td>228</td>\n",
       "      <td>117</td>\n",
       "      <td>228</td>\n",
       "      <td>...</td>\n",
       "      <td>117</td>\n",
       "      <td>172</td>\n",
       "      <td>117</td>\n",
       "      <td>172</td>\n",
       "      <td>117</td>\n",
       "      <td>172</td>\n",
       "      <td>117</td>\n",
       "      <td>172</td>\n",
       "      <td>117</td>\n",
       "      <td>172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>82</td>\n",
       "      <td>240</td>\n",
       "      <td>117</td>\n",
       "      <td>240</td>\n",
       "      <td>117</td>\n",
       "      <td>240</td>\n",
       "      <td>117</td>\n",
       "      <td>240</td>\n",
       "      <td>117</td>\n",
       "      <td>...</td>\n",
       "      <td>261</td>\n",
       "      <td>208</td>\n",
       "      <td>240</td>\n",
       "      <td>117</td>\n",
       "      <td>260</td>\n",
       "      <td>40</td>\n",
       "      <td>209</td>\n",
       "      <td>260</td>\n",
       "      <td>40</td>\n",
       "      <td>209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>82</td>\n",
       "      <td>240</td>\n",
       "      <td>117</td>\n",
       "      <td>240</td>\n",
       "      <td>117</td>\n",
       "      <td>240</td>\n",
       "      <td>117</td>\n",
       "      <td>240</td>\n",
       "      <td>117</td>\n",
       "      <td>...</td>\n",
       "      <td>260</td>\n",
       "      <td>141</td>\n",
       "      <td>260</td>\n",
       "      <td>141</td>\n",
       "      <td>260</td>\n",
       "      <td>141</td>\n",
       "      <td>260</td>\n",
       "      <td>141</td>\n",
       "      <td>260</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   malware  t_0  t_1  t_2  t_3  t_4  t_5  t_6  t_7  t_8  ...  t_90  t_91  \\\n",
       "0        1   82  240  117  240  117  240  117  240  117  ...   172   117   \n",
       "1        1  286  110  172  240  117  240  117  240  117  ...    65   202   \n",
       "2        1   82  172  117   16   29  208  228  117  228  ...   117   172   \n",
       "3        1   82  240  117  240  117  240  117  240  117  ...   261   208   \n",
       "4        1   82  240  117  240  117  240  117  240  117  ...   260   141   \n",
       "\n",
       "   t_92  t_93  t_94  t_95  t_96  t_97  t_98  t_99  \n",
       "0    93   208    16    31   215   108   215    35  \n",
       "1    65   117   260   297   215   114   215    71  \n",
       "2   117   172   117   172   117   172   117   172  \n",
       "3   240   117   260    40   209   260    40   209  \n",
       "4   260   141   260   141   260   141   260   141  \n",
       "\n",
       "[5 rows x 101 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>malware</th>\n",
       "      <th>t_0</th>\n",
       "      <th>t_1</th>\n",
       "      <th>t_2</th>\n",
       "      <th>t_3</th>\n",
       "      <th>t_4</th>\n",
       "      <th>t_5</th>\n",
       "      <th>t_6</th>\n",
       "      <th>t_7</th>\n",
       "      <th>t_8</th>\n",
       "      <th>...</th>\n",
       "      <th>t_90</th>\n",
       "      <th>t_91</th>\n",
       "      <th>t_92</th>\n",
       "      <th>t_93</th>\n",
       "      <th>t_94</th>\n",
       "      <th>t_95</th>\n",
       "      <th>t_96</th>\n",
       "      <th>t_97</th>\n",
       "      <th>t_98</th>\n",
       "      <th>t_99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>0</td>\n",
       "      <td>240</td>\n",
       "      <td>117</td>\n",
       "      <td>240</td>\n",
       "      <td>117</td>\n",
       "      <td>240</td>\n",
       "      <td>117</td>\n",
       "      <td>240</td>\n",
       "      <td>117</td>\n",
       "      <td>240</td>\n",
       "      <td>...</td>\n",
       "      <td>215</td>\n",
       "      <td>274</td>\n",
       "      <td>158</td>\n",
       "      <td>215</td>\n",
       "      <td>274</td>\n",
       "      <td>158</td>\n",
       "      <td>215</td>\n",
       "      <td>274</td>\n",
       "      <td>158</td>\n",
       "      <td>215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>0</td>\n",
       "      <td>82</td>\n",
       "      <td>274</td>\n",
       "      <td>158</td>\n",
       "      <td>215</td>\n",
       "      <td>86</td>\n",
       "      <td>82</td>\n",
       "      <td>37</td>\n",
       "      <td>70</td>\n",
       "      <td>37</td>\n",
       "      <td>...</td>\n",
       "      <td>158</td>\n",
       "      <td>215</td>\n",
       "      <td>82</td>\n",
       "      <td>240</td>\n",
       "      <td>117</td>\n",
       "      <td>82</td>\n",
       "      <td>240</td>\n",
       "      <td>117</td>\n",
       "      <td>297</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>0</td>\n",
       "      <td>82</td>\n",
       "      <td>16</td>\n",
       "      <td>31</td>\n",
       "      <td>122</td>\n",
       "      <td>194</td>\n",
       "      <td>260</td>\n",
       "      <td>117</td>\n",
       "      <td>141</td>\n",
       "      <td>117</td>\n",
       "      <td>...</td>\n",
       "      <td>117</td>\n",
       "      <td>172</td>\n",
       "      <td>117</td>\n",
       "      <td>172</td>\n",
       "      <td>117</td>\n",
       "      <td>172</td>\n",
       "      <td>117</td>\n",
       "      <td>172</td>\n",
       "      <td>117</td>\n",
       "      <td>172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>0</td>\n",
       "      <td>82</td>\n",
       "      <td>208</td>\n",
       "      <td>187</td>\n",
       "      <td>208</td>\n",
       "      <td>172</td>\n",
       "      <td>117</td>\n",
       "      <td>172</td>\n",
       "      <td>208</td>\n",
       "      <td>93</td>\n",
       "      <td>...</td>\n",
       "      <td>50</td>\n",
       "      <td>260</td>\n",
       "      <td>141</td>\n",
       "      <td>65</td>\n",
       "      <td>260</td>\n",
       "      <td>141</td>\n",
       "      <td>65</td>\n",
       "      <td>141</td>\n",
       "      <td>297</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000</th>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>230</td>\n",
       "      <td>248</td>\n",
       "      <td>128</td>\n",
       "      <td>248</td>\n",
       "      <td>128</td>\n",
       "      <td>274</td>\n",
       "      <td>158</td>\n",
       "      <td>120</td>\n",
       "      <td>...</td>\n",
       "      <td>158</td>\n",
       "      <td>215</td>\n",
       "      <td>278</td>\n",
       "      <td>274</td>\n",
       "      <td>158</td>\n",
       "      <td>215</td>\n",
       "      <td>278</td>\n",
       "      <td>274</td>\n",
       "      <td>158</td>\n",
       "      <td>215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2983</th>\n",
       "      <td>0</td>\n",
       "      <td>82</td>\n",
       "      <td>172</td>\n",
       "      <td>117</td>\n",
       "      <td>16</td>\n",
       "      <td>198</td>\n",
       "      <td>208</td>\n",
       "      <td>187</td>\n",
       "      <td>208</td>\n",
       "      <td>187</td>\n",
       "      <td>...</td>\n",
       "      <td>172</td>\n",
       "      <td>117</td>\n",
       "      <td>172</td>\n",
       "      <td>117</td>\n",
       "      <td>172</td>\n",
       "      <td>117</td>\n",
       "      <td>208</td>\n",
       "      <td>240</td>\n",
       "      <td>117</td>\n",
       "      <td>208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2984</th>\n",
       "      <td>0</td>\n",
       "      <td>215</td>\n",
       "      <td>274</td>\n",
       "      <td>158</td>\n",
       "      <td>215</td>\n",
       "      <td>274</td>\n",
       "      <td>158</td>\n",
       "      <td>215</td>\n",
       "      <td>172</td>\n",
       "      <td>117</td>\n",
       "      <td>...</td>\n",
       "      <td>240</td>\n",
       "      <td>117</td>\n",
       "      <td>15</td>\n",
       "      <td>117</td>\n",
       "      <td>15</td>\n",
       "      <td>240</td>\n",
       "      <td>117</td>\n",
       "      <td>240</td>\n",
       "      <td>117</td>\n",
       "      <td>240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2985</th>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>211</td>\n",
       "      <td>178</td>\n",
       "      <td>164</td>\n",
       "      <td>167</td>\n",
       "      <td>76</td>\n",
       "      <td>250</td>\n",
       "      <td>129</td>\n",
       "      <td>254</td>\n",
       "      <td>...</td>\n",
       "      <td>274</td>\n",
       "      <td>158</td>\n",
       "      <td>215</td>\n",
       "      <td>274</td>\n",
       "      <td>158</td>\n",
       "      <td>215</td>\n",
       "      <td>274</td>\n",
       "      <td>158</td>\n",
       "      <td>215</td>\n",
       "      <td>274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2986</th>\n",
       "      <td>0</td>\n",
       "      <td>208</td>\n",
       "      <td>187</td>\n",
       "      <td>208</td>\n",
       "      <td>93</td>\n",
       "      <td>208</td>\n",
       "      <td>172</td>\n",
       "      <td>117</td>\n",
       "      <td>82</td>\n",
       "      <td>60</td>\n",
       "      <td>...</td>\n",
       "      <td>225</td>\n",
       "      <td>35</td>\n",
       "      <td>60</td>\n",
       "      <td>81</td>\n",
       "      <td>35</td>\n",
       "      <td>225</td>\n",
       "      <td>35</td>\n",
       "      <td>225</td>\n",
       "      <td>215</td>\n",
       "      <td>260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2987</th>\n",
       "      <td>0</td>\n",
       "      <td>240</td>\n",
       "      <td>117</td>\n",
       "      <td>240</td>\n",
       "      <td>117</td>\n",
       "      <td>240</td>\n",
       "      <td>117</td>\n",
       "      <td>240</td>\n",
       "      <td>117</td>\n",
       "      <td>240</td>\n",
       "      <td>...</td>\n",
       "      <td>172</td>\n",
       "      <td>117</td>\n",
       "      <td>172</td>\n",
       "      <td>117</td>\n",
       "      <td>172</td>\n",
       "      <td>117</td>\n",
       "      <td>172</td>\n",
       "      <td>117</td>\n",
       "      <td>172</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>992 rows × 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      malware  t_0  t_1  t_2  t_3  t_4  t_5  t_6  t_7  t_8  ...  t_90  t_91  \\\n",
       "1996        0  240  117  240  117  240  117  240  117  240  ...   215   274   \n",
       "1997        0   82  274  158  215   86   82   37   70   37  ...   158   215   \n",
       "1998        0   82   16   31  122  194  260  117  141  117  ...   117   172   \n",
       "1999        0   82  208  187  208  172  117  172  208   93  ...    50   260   \n",
       "2000        0   16  230  248  128  248  128  274  158  120  ...   158   215   \n",
       "...       ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   ...   ...   \n",
       "2983        0   82  172  117   16  198  208  187  208  187  ...   172   117   \n",
       "2984        0  215  274  158  215  274  158  215  172  117  ...   240   117   \n",
       "2985        0   16  211  178  164  167   76  250  129  254  ...   274   158   \n",
       "2986        0  208  187  208   93  208  172  117   82   60  ...   225    35   \n",
       "2987        0  240  117  240  117  240  117  240  117  240  ...   172   117   \n",
       "\n",
       "      t_92  t_93  t_94  t_95  t_96  t_97  t_98  t_99  \n",
       "1996   158   215   274   158   215   274   158   215  \n",
       "1997    82   240   117    82   240   117   297     8  \n",
       "1998   117   172   117   172   117   172   117   172  \n",
       "1999   141    65   260   141    65   141   297    47  \n",
       "2000   278   274   158   215   278   274   158   215  \n",
       "...    ...   ...   ...   ...   ...   ...   ...   ...  \n",
       "2983   172   117   172   117   208   240   117   208  \n",
       "2984    15   117    15   240   117   240   117   240  \n",
       "2985   215   274   158   215   274   158   215   274  \n",
       "2986    60    81    35   225    35   225   215   260  \n",
       "2987   172   117   172   117   172   117   172   117  \n",
       "\n",
       "[992 rows x 101 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from imblearn.combine import SMOTETomek\n",
    "\n",
    "smt = SMOTETomek(random_state=1, n_jobs=8, sampling_strategy=0.5)\n",
    "\n",
    "X = train_tb.iloc[:,1:101]\n",
    "y = train_tb.iloc[:,0]\n",
    "\n",
    "X_res, y_res = smt.fit_resample(X, y)\n",
    "train_tb = pd.concat([y_res,X_res], axis=1)\n",
    "print(train_tb.shape)\n",
    "print(train_tb['malware'].value_counts())\n",
    "display(train_tb.head())\n",
    "display(train_tb[train_tb['malware']==0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating IB versions of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-10T13:34:21.799811Z",
     "iopub.status.busy": "2024-04-10T13:34:21.799811Z",
     "iopub.status.idle": "2024-04-10T13:41:24.190847Z",
     "shell.execute_reply": "2024-04-10T13:41:24.190847Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transposing IB...\n",
      "IB Transposed!\n",
      "Removing duplicates...\n",
      "Row: 0 100 200 300 400 500 600 700 800 900 1000 1100 1200 1300 1400 1500 1600 1700 1800 1900 2000 2100 2200 2300 2400 2500 2600 2700 2800 2900 \n",
      "Duplicates removed!\n",
      "Retransposing IB (revert)...\n",
      "IB Retransposed!\n",
      "\n",
      "\n",
      "Transposing IB...\n",
      "IB Transposed!\n",
      "Removing duplicates...\n",
      "Row: 0 100 200 300 400 500 600 700 800 900 1000 1100 1200 1300 1400 1500 1600 1700 1800 1900 2000 2100 2200 2300 2400 2500 2600 2700 2800 2900 3000 3100 3200 3300 3400 3500 3600 3700 3800 3900 4000 4100 4200 4300 4400 4500 4600 4700 4800 4900 5000 5100 5200 5300 5400 5500 5600 5700 5800 5900 6000 6100 6200 6300 6400 6500 6600 6700 6800 6900 7000 7100 7200 7300 7400 7500 7600 7700 7800 7900 8000 8100 8200 8300 8400 8500 8600 8700 8800 8900 9000 9100 9200 9300 9400 9500 9600 9700 9800 9900 10000 10100 10200 10300 10400 10500 10600 10700 10800 10900 11000 11100 11200 11300 11400 11500 11600 11700 11800 11900 12000 12100 12200 12300 12400 12500 12600 12700 12800 12900 13000 13100 13200 13300 13400 13500 13600 13700 13800 13900 14000 14100 14200 14300 14400 14500 14600 14700 14800 14900 15000 15100 15200 15300 15400 15500 15600 15700 15800 15900 16000 16100 16200 16300 16400 16500 16600 16700 16800 16900 17000 17100 17200 17300 17400 17500 17600 17700 17800 17900 18000 18100 18200 18300 18400 18500 18600 18700 18800 18900 19000 19100 19200 19300 19400 19500 19600 19700 19800 19900 20000 20100 20200 20300 20400 20500 20600 20700 20800 20900 21000 21100 21200 21300 21400 21500 21600 21700 21800 21900 22000 22100 22200 22300 22400 22500 22600 22700 22800 22900 23000 23100 23200 23300 23400 23500 23600 23700 23800 23900 24000 24100 24200 24300 24400 24500 24600 24700 24800 24900 25000 25100 25200 25300 25400 25500 25600 25700 25800 25900 26000 26100 26200 26300 26400 26500 26600 26700 26800 26900 27000 27100 27200 27300 27400 27500 27600 27700 27800 27900 28000 28100 28200 28300 28400 28500 28600 28700 28800 28900 29000 29100 29200 29300 29400 29500 29600 29700 29800 29900 30000 30100 30200 30300 30400 30500 30600 30700 30800 30900 31000 31100 31200 31300 31400 31500 31600 31700 31800 31900 32000 32100 32200 32300 32400 32500 32600 32700 32800 32900 33000 33100 33200 33300 33400 33500 33600 33700 33800 33900 34000 34100 34200 34300 34400 34500 34600 34700 34800 34900 35000 35100 35200 35300 35400 35500 35600 35700 35800 35900 36000 36100 36200 36300 36400 36500 36600 36700 36800 36900 37000 37100 37200 37300 37400 37500 37600 37700 37800 37900 38000 38100 38200 \n",
      "Duplicates removed!\n",
      "Retransposing IB (revert)...\n",
      "IB Retransposed!\n"
     ]
    }
   ],
   "source": [
    "train_ib = train_tb.copy(deep=True)\n",
    "test_ib = test_tb.copy(deep=True)\n",
    "\n",
    "train_ib = ib_convert(train_ib).copy(deep=True)\n",
    "print(\"\\n\")\n",
    "test_ib = ib_convert(test_ib).copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-10T13:41:24.190847Z",
     "iopub.status.busy": "2024-04-10T13:41:24.190847Z",
     "iopub.status.idle": "2024-04-10T13:41:24.199373Z",
     "shell.execute_reply": "2024-04-10T13:41:24.199373Z"
    }
   },
   "outputs": [],
   "source": [
    "# train_ib.iloc[:,1:101] = train_ib.iloc[:,1:101].astype('str')\n",
    "# train_ib.replace(\"nan\", \"NaN\", inplace=True)\n",
    "# test_ib.iloc[:,1:101] = test_ib.iloc[:,1:101].astype('str')\n",
    "# test_ib.replace(\"nan\", \"NaN\", inplace=True)\n",
    "# display(train_ib.head())\n",
    "# display(test_ib.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting results to usable for models\n",
    "\n",
    "Encoded APIs to Unencoded/String APIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-10T13:41:24.199373Z",
     "iopub.status.busy": "2024-04-10T13:41:24.199373Z",
     "iopub.status.idle": "2024-04-10T13:41:24.207925Z",
     "shell.execute_reply": "2024-04-10T13:41:24.207925Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# train_tb_enc = train_tb.copy(deep=True)\n",
    "# test_tb_enc = test_tb.copy(deep=True)\n",
    "# train_ib_enc = train_ib.copy(deep=True)\n",
    "# test_ib_enc = test_ib.copy(deep=True)\n",
    "\n",
    "# train_tb_enc.iloc[:, 1:101] = train_tb.iloc[:, 1:101].apply(inverse_label, axis=1, result_type='reduce')\n",
    "# test_tb_enc.iloc[:, 1:101] = test_tb.iloc[:, 1:101].apply(inverse_label, axis=1, result_type='reduce')\n",
    "# train_ib_enc.iloc[:, 1:101] = train_ib.iloc[:, 1:101].apply(inverse_label, axis=1, result_type='reduce')\n",
    "# test_ib_enc.iloc[:, 1:101] = test_ib.iloc[:, 1:101].apply(inverse_label, axis=1, result_type='reduce')\n",
    "\n",
    "# display(train_tb_enc.head())\n",
    "# display(test_tb_enc.head())\n",
    "# display(train_ib_enc.head())\n",
    "# display(test_ib_enc.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying it out on LightGBM, CatBoost, and SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-10T13:41:24.207925Z",
     "iopub.status.busy": "2024-04-10T13:41:24.207925Z",
     "iopub.status.idle": "2024-04-10T13:41:24.222158Z",
     "shell.execute_reply": "2024-04-10T13:41:24.222158Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_indexes():\n",
    "    indexes = []\n",
    "    for i in range(100):\n",
    "        indexes.append(f\"t_{i}\")\n",
    "    return indexes\n",
    "\n",
    "def train_test(train, test, model, model_str:str):\n",
    "    X = train.iloc[:,1:101]\n",
    "    y = train.iloc[:,0]\n",
    "    X_test = test.iloc[:,1:101]\n",
    "    y_test = test.iloc[:,0]\n",
    "    print(f\"Model: {model_str}\")\n",
    "    #MODEL ROBUSTNESS\n",
    "    model.fit(X,y)\n",
    "    y_pred = model.predict(X_test)\n",
    "    #print(\"\\nModel, Fold, Accuracy, Precision, F1-Score, Recall, ROC-AUC\")\n",
    "    #print(f\"{model_str}, {'T'}, {metrics.accuracy_score(y_test, y_pred):.4f}, {metrics.average_precision_score(y_test, y_pred):.4f}, {metrics.f1_score(y_test, y_pred):.4f}, {metrics.recall_score(y_test, y_pred):.4f}, {metrics.roc_auc_score(y_test, y_pred):.4f}\")\n",
    "    print(f\"Fold: T\")\n",
    "    print(classification_report(y_test, y_pred, digits=4))\n",
    "    print(f\"ROC-AUC: {metrics.roc_auc_score(y_test, y_pred):.4f}\")\n",
    "    #STRATIFIED K-FOLDS\n",
    "    skf = StratifiedKFold(n_splits=5, random_state=1, shuffle=True)\n",
    "    ctr = 0\n",
    "    for train_idx, test_idx in skf.split(train.iloc[:,1:101], train.iloc[:,0]):\n",
    "        X_train = train.iloc[train_idx, 1:101]\n",
    "        y_train = train.iloc[train_idx, 0]\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(train.iloc[test_idx, 1:101])\n",
    "        y_test = train.iloc[test_idx, 0]\n",
    "        #print(f\"{model_str}, {ctr}, {metrics.accuracy_score(y_test, y_pred):.4f}, {metrics.average_precision_score(y_test, y_pred):.4f}, {metrics.f1_score(y_test, y_pred):.4f}, {metrics.recall_score(y_test, y_pred):.4f}, {metrics.roc_auc_score(y_test, y_pred):.4f}\")\n",
    "        print(f\"Fold: {ctr}\")\n",
    "        print(classification_report(y_test, y_pred, digits=4))\n",
    "        ctr += 1\n",
    "    print('-------------------------------------------------------')\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-10T13:41:24.222158Z",
     "iopub.status.busy": "2024-04-10T13:41:24.222158Z",
     "iopub.status.idle": "2024-04-10T13:42:19.292647Z",
     "shell.execute_reply": "2024-04-10T13:42:19.292647Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: LGBM TB\n",
      "Fold: T\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0469    0.8289    0.0889        76\n",
      "           1     0.9996    0.9665    0.9828     38151\n",
      "\n",
      "    accuracy                         0.9662     38227\n",
      "   macro avg     0.5233    0.8977    0.5358     38227\n",
      "weighted avg     0.9978    0.9662    0.9810     38227\n",
      "\n",
      "ROC-AUC: 0.8977\n",
      "Fold: 0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9066    0.8333    0.8684       198\n",
      "           1     0.9207    0.9575    0.9387       400\n",
      "\n",
      "    accuracy                         0.9164       598\n",
      "   macro avg     0.9136    0.8954    0.9036       598\n",
      "weighted avg     0.9160    0.9164    0.9154       598\n",
      "\n",
      "Fold: 1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8844    0.8844    0.8844       199\n",
      "           1     0.9424    0.9424    0.9424       399\n",
      "\n",
      "    accuracy                         0.9231       598\n",
      "   macro avg     0.9134    0.9134    0.9134       598\n",
      "weighted avg     0.9231    0.9231    0.9231       598\n",
      "\n",
      "Fold: 2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9101    0.8643    0.8866       199\n",
      "           1     0.9340    0.9574    0.9455       399\n",
      "\n",
      "    accuracy                         0.9264       598\n",
      "   macro avg     0.9220    0.9109    0.9161       598\n",
      "weighted avg     0.9260    0.9264    0.9259       598\n",
      "\n",
      "Fold: 3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9235    0.8535    0.8871       198\n",
      "           1     0.9300    0.9649    0.9471       399\n",
      "\n",
      "    accuracy                         0.9280       597\n",
      "   macro avg     0.9267    0.9092    0.9171       597\n",
      "weighted avg     0.9278    0.9280    0.9272       597\n",
      "\n",
      "Fold: 4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9243    0.8636    0.8930       198\n",
      "           1     0.9345    0.9649    0.9494       399\n",
      "\n",
      "    accuracy                         0.9313       597\n",
      "   macro avg     0.9294    0.9143    0.9212       597\n",
      "weighted avg     0.9311    0.9313    0.9307       597\n",
      "\n",
      "-------------------------------------------------------\n",
      "\n",
      "Model: CATB TB\n",
      "Fold: T\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0553    0.8289    0.1036        76\n",
      "           1     0.9996    0.9718    0.9855     38151\n",
      "\n",
      "    accuracy                         0.9715     38227\n",
      "   macro avg     0.5275    0.9004    0.5446     38227\n",
      "weighted avg     0.9978    0.9715    0.9838     38227\n",
      "\n",
      "ROC-AUC: 0.9004\n",
      "Fold: 0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9231    0.7879    0.8501       198\n",
      "           1     0.9021    0.9675    0.9337       400\n",
      "\n",
      "    accuracy                         0.9080       598\n",
      "   macro avg     0.9126    0.8777    0.8919       598\n",
      "weighted avg     0.9090    0.9080    0.9060       598\n",
      "\n",
      "Fold: 1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9301    0.8693    0.8987       199\n",
      "           1     0.9369    0.9674    0.9519       399\n",
      "\n",
      "    accuracy                         0.9348       598\n",
      "   macro avg     0.9335    0.9184    0.9253       598\n",
      "weighted avg     0.9346    0.9348    0.9342       598\n",
      "\n",
      "Fold: 2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9341    0.8543    0.8924       199\n",
      "           1     0.9303    0.9699    0.9497       399\n",
      "\n",
      "    accuracy                         0.9314       598\n",
      "   macro avg     0.9322    0.9121    0.9210       598\n",
      "weighted avg     0.9315    0.9314    0.9306       598\n",
      "\n",
      "Fold: 3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9364    0.8182    0.8733       198\n",
      "           1     0.9151    0.9724    0.9429       399\n",
      "\n",
      "    accuracy                         0.9213       597\n",
      "   macro avg     0.9258    0.8953    0.9081       597\n",
      "weighted avg     0.9222    0.9213    0.9198       597\n",
      "\n",
      "Fold: 4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9486    0.8384    0.8901       198\n",
      "           1     0.9242    0.9774    0.9501       399\n",
      "\n",
      "    accuracy                         0.9313       597\n",
      "   macro avg     0.9364    0.9079    0.9201       597\n",
      "weighted avg     0.9323    0.9313    0.9302       597\n",
      "\n",
      "-------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_test(train_tb, test_tb, lgbm.LGBMClassifier(random_state=1, n_jobs=0, verbose=0), \"LGBM TB\")\n",
    "train_test(train_tb, test_tb, catb.CatBoostClassifier(random_state=1, thread_count=-1, verbose=0, cat_features=get_indexes(), \n",
    "                                                    nan_mode='Min', one_hot_max_size=256), \"CATB TB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-10T13:42:19.292647Z",
     "iopub.status.busy": "2024-04-10T13:42:19.292647Z",
     "iopub.status.idle": "2024-04-10T13:42:50.102780Z",
     "shell.execute_reply": "2024-04-10T13:42:50.102780Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: LGBM IB\n",
      "Fold: T\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0372    0.8289    0.0712        76\n",
      "           1     0.9996    0.9573    0.9780     38151\n",
      "\n",
      "    accuracy                         0.9570     38227\n",
      "   macro avg     0.5184    0.8931    0.5246     38227\n",
      "weighted avg     0.9977    0.9570    0.9762     38227\n",
      "\n",
      "ROC-AUC: 0.8931\n",
      "Fold: 0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8918    0.8737    0.8827       198\n",
      "           1     0.9381    0.9475    0.9428       400\n",
      "\n",
      "    accuracy                         0.9231       598\n",
      "   macro avg     0.9149    0.9106    0.9127       598\n",
      "weighted avg     0.9228    0.9231    0.9229       598\n",
      "\n",
      "Fold: 1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9072    0.8844    0.8957       199\n",
      "           1     0.9431    0.9549    0.9489       399\n",
      "\n",
      "    accuracy                         0.9314       598\n",
      "   macro avg     0.9251    0.9197    0.9223       598\n",
      "weighted avg     0.9311    0.9314    0.9312       598\n",
      "\n",
      "Fold: 2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9351    0.8693    0.9010       199\n",
      "           1     0.9370    0.9699    0.9532       399\n",
      "\n",
      "    accuracy                         0.9365       598\n",
      "   macro avg     0.9361    0.9196    0.9271       598\n",
      "weighted avg     0.9364    0.9365    0.9358       598\n",
      "\n",
      "Fold: 3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8878    0.8788    0.8832       198\n",
      "           1     0.9401    0.9449    0.9425       399\n",
      "\n",
      "    accuracy                         0.9229       597\n",
      "   macro avg     0.9140    0.9118    0.9129       597\n",
      "weighted avg     0.9228    0.9229    0.9228       597\n",
      "\n",
      "Fold: 4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8673    0.8586    0.8629       198\n",
      "           1     0.9302    0.9348    0.9325       399\n",
      "\n",
      "    accuracy                         0.9095       597\n",
      "   macro avg     0.8988    0.8967    0.8977       597\n",
      "weighted avg     0.9093    0.9095    0.9094       597\n",
      "\n",
      "-------------------------------------------------------\n",
      "\n",
      "Model: CATB IB\n",
      "Fold: T\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0591    0.7895    0.1100        76\n",
      "           1     0.9996    0.9750    0.9871     38151\n",
      "\n",
      "    accuracy                         0.9746     38227\n",
      "   macro avg     0.5293    0.8822    0.5486     38227\n",
      "weighted avg     0.9977    0.9746    0.9854     38227\n",
      "\n",
      "ROC-AUC: 0.8822\n",
      "Fold: 0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9353    0.8030    0.8641       198\n",
      "           1     0.9089    0.9725    0.9396       400\n",
      "\n",
      "    accuracy                         0.9164       598\n",
      "   macro avg     0.9221    0.8878    0.9019       598\n",
      "weighted avg     0.9176    0.9164    0.9146       598\n",
      "\n",
      "Fold: 1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9527    0.8090    0.8750       199\n",
      "           1     0.9114    0.9799    0.9444       399\n",
      "\n",
      "    accuracy                         0.9231       598\n",
      "   macro avg     0.9320    0.8945    0.9097       598\n",
      "weighted avg     0.9251    0.9231    0.9213       598\n",
      "\n",
      "Fold: 2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9767    0.8442    0.9057       199\n",
      "           1     0.9272    0.9900    0.9576       399\n",
      "\n",
      "    accuracy                         0.9415       598\n",
      "   macro avg     0.9520    0.9171    0.9316       598\n",
      "weighted avg     0.9437    0.9415    0.9403       598\n",
      "\n",
      "Fold: 3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9375    0.8333    0.8824       198\n",
      "           1     0.9216    0.9724    0.9463       399\n",
      "\n",
      "    accuracy                         0.9263       597\n",
      "   macro avg     0.9296    0.9029    0.9143       597\n",
      "weighted avg     0.9269    0.9263    0.9251       597\n",
      "\n",
      "Fold: 4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9032    0.8485    0.8750       198\n",
      "           1     0.9270    0.9549    0.9407       399\n",
      "\n",
      "    accuracy                         0.9196       597\n",
      "   macro avg     0.9151    0.9017    0.9079       597\n",
      "weighted avg     0.9191    0.9196    0.9189       597\n",
      "\n",
      "-------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_test(train_ib, test_ib, lgbm.LGBMClassifier(random_state=1, n_jobs=0,verbose=0), \"LGBM IB\")\n",
    "train_test(train_ib, test_ib, catb.CatBoostClassifier(random_state=1, thread_count=-1, verbose=0, cat_features=get_indexes(), \n",
    "                                                    nan_mode='Min', one_hot_max_size=256), \"CATB IB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-10T13:42:50.102780Z",
     "iopub.status.busy": "2024-04-10T13:42:50.102780Z",
     "iopub.status.idle": "2024-04-10T13:43:10.951740Z",
     "shell.execute_reply": "2024-04-10T13:43:10.951740Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: SVM TB\n",
      "Fold: T\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0329    0.8158    0.0632        76\n",
      "           1     0.9996    0.9522    0.9753     38151\n",
      "\n",
      "    accuracy                         0.9519     38227\n",
      "   macro avg     0.5163    0.8840    0.5193     38227\n",
      "weighted avg     0.9977    0.9519    0.9735     38227\n",
      "\n",
      "ROC-AUC: 0.8840\n",
      "Fold: 0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8978    0.8434    0.8698       198\n",
      "           1     0.9248    0.9525    0.9384       400\n",
      "\n",
      "    accuracy                         0.9164       598\n",
      "   macro avg     0.9113    0.8980    0.9041       598\n",
      "weighted avg     0.9158    0.9164    0.9157       598\n",
      "\n",
      "Fold: 1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8737    0.8693    0.8715       199\n",
      "           1     0.9350    0.9373    0.9362       399\n",
      "\n",
      "    accuracy                         0.9147       598\n",
      "   macro avg     0.9044    0.9033    0.9039       598\n",
      "weighted avg     0.9146    0.9147    0.9147       598\n",
      "\n",
      "Fold: 2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9235    0.8492    0.8848       199\n",
      "           1     0.9277    0.9649    0.9459       399\n",
      "\n",
      "    accuracy                         0.9264       598\n",
      "   macro avg     0.9256    0.9071    0.9154       598\n",
      "weighted avg     0.9263    0.9264    0.9256       598\n",
      "\n",
      "Fold: 3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9333    0.8485    0.8889       198\n",
      "           1     0.9281    0.9699    0.9485       399\n",
      "\n",
      "    accuracy                         0.9296       597\n",
      "   macro avg     0.9307    0.9092    0.9187       597\n",
      "weighted avg     0.9298    0.9296    0.9287       597\n",
      "\n",
      "Fold: 4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8942    0.8535    0.8734       198\n",
      "           1     0.9289    0.9499    0.9393       399\n",
      "\n",
      "    accuracy                         0.9179       597\n",
      "   macro avg     0.9116    0.9017    0.9063       597\n",
      "weighted avg     0.9174    0.9179    0.9174       597\n",
      "\n",
      "-------------------------------------------------------\n",
      "\n",
      "Model: MLPC TB\n",
      "Fold: T\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0220    0.8553    0.0428        76\n",
      "           1     0.9997    0.9241    0.9604     38151\n",
      "\n",
      "    accuracy                         0.9240     38227\n",
      "   macro avg     0.5108    0.8897    0.5016     38227\n",
      "weighted avg     0.9977    0.9240    0.9586     38227\n",
      "\n",
      "ROC-AUC: 0.8897\n",
      "Fold: 0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8272    0.7980    0.8123       198\n",
      "           1     0.9017    0.9175    0.9095       400\n",
      "\n",
      "    accuracy                         0.8779       598\n",
      "   macro avg     0.8645    0.8577    0.8609       598\n",
      "weighted avg     0.8771    0.8779    0.8774       598\n",
      "\n",
      "Fold: 1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8966    0.7839    0.8365       199\n",
      "           1     0.8986    0.9549    0.9259       399\n",
      "\n",
      "    accuracy                         0.8980       598\n",
      "   macro avg     0.8976    0.8694    0.8812       598\n",
      "weighted avg     0.8979    0.8980    0.8961       598\n",
      "\n",
      "Fold: 2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8359    0.8191    0.8274       199\n",
      "           1     0.9107    0.9198    0.9152       399\n",
      "\n",
      "    accuracy                         0.8863       598\n",
      "   macro avg     0.8733    0.8694    0.8713       598\n",
      "weighted avg     0.8858    0.8863    0.8860       598\n",
      "\n",
      "Fold: 3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8350    0.8434    0.8392       198\n",
      "           1     0.9219    0.9173    0.9196       399\n",
      "\n",
      "    accuracy                         0.8928       597\n",
      "   macro avg     0.8785    0.8804    0.8794       597\n",
      "weighted avg     0.8931    0.8928    0.8929       597\n",
      "\n",
      "Fold: 4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9624    0.6465    0.7734       198\n",
      "           1     0.8491    0.9875    0.9131       399\n",
      "\n",
      "    accuracy                         0.8744       597\n",
      "   macro avg     0.9058    0.8170    0.8433       597\n",
      "weighted avg     0.8867    0.8744    0.8668       597\n",
      "\n",
      "-------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_test(train_tb, test_tb, svc.SVC(random_state=1, verbose=0, cache_size=1024), \"SVM TB\")\n",
    "train_test(train_tb, test_tb, mlpc.MLPClassifier(random_state=1, verbose=0), \"MLPC TB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-10T13:43:10.951740Z",
     "iopub.status.busy": "2024-04-10T13:43:10.951740Z",
     "iopub.status.idle": "2024-04-10T13:43:24.166281Z",
     "shell.execute_reply": "2024-04-10T13:43:24.166281Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: SVM IB\n",
      "Fold: T\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0258    0.7237    0.0498        76\n",
      "           1     0.9994    0.9455    0.9717     38151\n",
      "\n",
      "    accuracy                         0.9451     38227\n",
      "   macro avg     0.5126    0.8346    0.5107     38227\n",
      "weighted avg     0.9975    0.9451    0.9699     38227\n",
      "\n",
      "ROC-AUC: 0.8346\n",
      "Fold: 0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8922    0.7525    0.8164       198\n",
      "           1     0.8863    0.9550    0.9194       400\n",
      "\n",
      "    accuracy                         0.8880       598\n",
      "   macro avg     0.8893    0.8538    0.8679       598\n",
      "weighted avg     0.8883    0.8880    0.8853       598\n",
      "\n",
      "Fold: 1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8678    0.7588    0.8097       199\n",
      "           1     0.8868    0.9424    0.9137       399\n",
      "\n",
      "    accuracy                         0.8813       598\n",
      "   macro avg     0.8773    0.8506    0.8617       598\n",
      "weighted avg     0.8805    0.8813    0.8791       598\n",
      "\n",
      "Fold: 2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9423    0.7387    0.8282       199\n",
      "           1     0.8824    0.9774    0.9275       399\n",
      "\n",
      "    accuracy                         0.8980       598\n",
      "   macro avg     0.9123    0.8581    0.8778       598\n",
      "weighted avg     0.9023    0.8980    0.8944       598\n",
      "\n",
      "Fold: 3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8192    0.7323    0.7733       198\n",
      "           1     0.8738    0.9198    0.8962       399\n",
      "\n",
      "    accuracy                         0.8576       597\n",
      "   macro avg     0.8465    0.8261    0.8348       597\n",
      "weighted avg     0.8557    0.8576    0.8555       597\n",
      "\n",
      "Fold: 4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8424    0.7828    0.8115       198\n",
      "           1     0.8959    0.9273    0.9113       399\n",
      "\n",
      "    accuracy                         0.8794       597\n",
      "   macro avg     0.8691    0.8551    0.8614       597\n",
      "weighted avg     0.8781    0.8794    0.8782       597\n",
      "\n",
      "-------------------------------------------------------\n",
      "\n",
      "Model: MLPC IB\n",
      "Fold: T\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0119    0.7632    0.0235        76\n",
      "           1     0.9995    0.8740    0.9325     38151\n",
      "\n",
      "    accuracy                         0.8738     38227\n",
      "   macro avg     0.5057    0.8186    0.4780     38227\n",
      "weighted avg     0.9975    0.8738    0.9307     38227\n",
      "\n",
      "ROC-AUC: 0.8186\n",
      "Fold: 0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8879    0.5202    0.6561       198\n",
      "           1     0.8029    0.9675    0.8776       400\n",
      "\n",
      "    accuracy                         0.8194       598\n",
      "   macro avg     0.8454    0.7439    0.7668       598\n",
      "weighted avg     0.8311    0.8194    0.8042       598\n",
      "\n",
      "Fold: 1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9065    0.6332    0.7456       199\n",
      "           1     0.8410    0.9674    0.8998       399\n",
      "\n",
      "    accuracy                         0.8562       598\n",
      "   macro avg     0.8737    0.8003    0.8227       598\n",
      "weighted avg     0.8628    0.8562    0.8485       598\n",
      "\n",
      "Fold: 2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6920    0.7789    0.7329       199\n",
      "           1     0.8824    0.8271    0.8538       399\n",
      "\n",
      "    accuracy                         0.8110       598\n",
      "   macro avg     0.7872    0.8030    0.7933       598\n",
      "weighted avg     0.8190    0.8110    0.8136       598\n",
      "\n",
      "Fold: 3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5887    0.7879    0.6739       198\n",
      "           1     0.8735    0.7268    0.7934       399\n",
      "\n",
      "    accuracy                         0.7471       597\n",
      "   macro avg     0.7311    0.7573    0.7336       597\n",
      "weighted avg     0.7790    0.7471    0.7538       597\n",
      "\n",
      "Fold: 4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9231    0.2424    0.3840       198\n",
      "           1     0.7248    0.9900    0.8369       399\n",
      "\n",
      "    accuracy                         0.7420       597\n",
      "   macro avg     0.8239    0.6162    0.6104       597\n",
      "weighted avg     0.7905    0.7420    0.6867       597\n",
      "\n",
      "-------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_test(train_ib, test_ib, svc.SVC(random_state=1, verbose=0, cache_size=1024), \"SVM IB\")\n",
    "train_test(train_ib, test_ib, mlpc.MLPClassifier(random_state=1, verbose=0), \"MLPC IB\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
