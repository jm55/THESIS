{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_COMPONENTS=68"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ejose\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\arrays\\masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hash</th>\n",
       "      <th>t_0</th>\n",
       "      <th>t_1</th>\n",
       "      <th>t_2</th>\n",
       "      <th>t_3</th>\n",
       "      <th>t_4</th>\n",
       "      <th>t_5</th>\n",
       "      <th>t_6</th>\n",
       "      <th>t_7</th>\n",
       "      <th>t_8</th>\n",
       "      <th>...</th>\n",
       "      <th>t_60</th>\n",
       "      <th>t_61</th>\n",
       "      <th>t_62</th>\n",
       "      <th>t_63</th>\n",
       "      <th>t_64</th>\n",
       "      <th>t_65</th>\n",
       "      <th>t_66</th>\n",
       "      <th>t_67</th>\n",
       "      <th>malware</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>071e8c3f8922e186e57548cd4c703a5d</td>\n",
       "      <td>112</td>\n",
       "      <td>274</td>\n",
       "      <td>158</td>\n",
       "      <td>215</td>\n",
       "      <td>274</td>\n",
       "      <td>158</td>\n",
       "      <td>215</td>\n",
       "      <td>298</td>\n",
       "      <td>76</td>\n",
       "      <td>...</td>\n",
       "      <td>60</td>\n",
       "      <td>81</td>\n",
       "      <td>60</td>\n",
       "      <td>81</td>\n",
       "      <td>225</td>\n",
       "      <td>35</td>\n",
       "      <td>60</td>\n",
       "      <td>81</td>\n",
       "      <td>1</td>\n",
       "      <td>trojan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33f8e6d08a6aae939f25a8e0d63dd523</td>\n",
       "      <td>82</td>\n",
       "      <td>208</td>\n",
       "      <td>187</td>\n",
       "      <td>208</td>\n",
       "      <td>172</td>\n",
       "      <td>117</td>\n",
       "      <td>172</td>\n",
       "      <td>117</td>\n",
       "      <td>172</td>\n",
       "      <td>...</td>\n",
       "      <td>208</td>\n",
       "      <td>35</td>\n",
       "      <td>215</td>\n",
       "      <td>35</td>\n",
       "      <td>208</td>\n",
       "      <td>240</td>\n",
       "      <td>117</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>pua</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b68abd064e975e1c6d5f25e748663076</td>\n",
       "      <td>16</td>\n",
       "      <td>110</td>\n",
       "      <td>240</td>\n",
       "      <td>117</td>\n",
       "      <td>240</td>\n",
       "      <td>117</td>\n",
       "      <td>240</td>\n",
       "      <td>117</td>\n",
       "      <td>240</td>\n",
       "      <td>...</td>\n",
       "      <td>123</td>\n",
       "      <td>65</td>\n",
       "      <td>112</td>\n",
       "      <td>123</td>\n",
       "      <td>65</td>\n",
       "      <td>112</td>\n",
       "      <td>123</td>\n",
       "      <td>65</td>\n",
       "      <td>1</td>\n",
       "      <td>trojan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>72049be7bd30ea61297ea624ae198067</td>\n",
       "      <td>82</td>\n",
       "      <td>208</td>\n",
       "      <td>187</td>\n",
       "      <td>208</td>\n",
       "      <td>172</td>\n",
       "      <td>117</td>\n",
       "      <td>172</td>\n",
       "      <td>117</td>\n",
       "      <td>172</td>\n",
       "      <td>...</td>\n",
       "      <td>158</td>\n",
       "      <td>215</td>\n",
       "      <td>240</td>\n",
       "      <td>117</td>\n",
       "      <td>82</td>\n",
       "      <td>240</td>\n",
       "      <td>117</td>\n",
       "      <td>240</td>\n",
       "      <td>1</td>\n",
       "      <td>trojan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>c9b3700a77facf29172f32df6bc77f48</td>\n",
       "      <td>82</td>\n",
       "      <td>240</td>\n",
       "      <td>117</td>\n",
       "      <td>240</td>\n",
       "      <td>117</td>\n",
       "      <td>240</td>\n",
       "      <td>117</td>\n",
       "      <td>240</td>\n",
       "      <td>117</td>\n",
       "      <td>...</td>\n",
       "      <td>141</td>\n",
       "      <td>65</td>\n",
       "      <td>260</td>\n",
       "      <td>141</td>\n",
       "      <td>65</td>\n",
       "      <td>31</td>\n",
       "      <td>159</td>\n",
       "      <td>224</td>\n",
       "      <td>1</td>\n",
       "      <td>trojan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 71 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               hash  t_0  t_1  t_2  t_3  t_4  t_5  t_6  t_7  \\\n",
       "0  071e8c3f8922e186e57548cd4c703a5d  112  274  158  215  274  158  215  298   \n",
       "1  33f8e6d08a6aae939f25a8e0d63dd523   82  208  187  208  172  117  172  117   \n",
       "2  b68abd064e975e1c6d5f25e748663076   16  110  240  117  240  117  240  117   \n",
       "3  72049be7bd30ea61297ea624ae198067   82  208  187  208  172  117  172  117   \n",
       "4  c9b3700a77facf29172f32df6bc77f48   82  240  117  240  117  240  117  240   \n",
       "\n",
       "   t_8  ...  t_60  t_61  t_62  t_63  t_64  t_65  t_66  t_67  malware    type  \n",
       "0   76  ...    60    81    60    81   225    35    60    81        1  trojan  \n",
       "1  172  ...   208    35   215    35   208   240   117    35        1     pua  \n",
       "2  240  ...   123    65   112   123    65   112   123    65        1  trojan  \n",
       "3  172  ...   158   215   240   117    82   240   117   240        1  trojan  \n",
       "4  117  ...   141    65   260   141    65    31   159   224        1  trojan  \n",
       "\n",
       "[5 rows x 71 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import Libraries\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import lightgbm as lgbm\n",
    "import catboost as catb\n",
    "import sklearn.svm as svc\n",
    "import sklearn.neural_network as mlpc\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "df = pd.read_csv('./Dataset/oliveira_labelled.csv')\n",
    "\n",
    "API_LIST = \"./Dataset/api_calls.txt\"\n",
    "DELIMITER = \"NaN\"\n",
    "API_FILE = open(API_LIST,\"r\")\n",
    "APIS = API_FILE.readline().split(',')\n",
    "APIS.append(DELIMITER) #serves as a label for NaN values for Instance-based datasets\n",
    "API_FILE.close()\n",
    "\n",
    "#Inverse Label Encoding\n",
    "def inverse_label(item:str):\n",
    "    global APIS\n",
    "    return item.map(lambda x: APIS[int(x)])\n",
    "\n",
    "def list_to_str(ls:list):\n",
    "    '''Convert list to a stringified version (comma delimited).'''\n",
    "    output = \"\"\n",
    "    for l in ls:\n",
    "        output += str(l) + \",\"\n",
    "    return output[0:len(output)-1]\n",
    "\n",
    "def inject_patterns(inner_df:pd.DataFrame):\n",
    "    '''Injects the API call patterns of each sample as its last column'''\n",
    "    patterns = []\n",
    "    print(\"Injecting API patterns...\")\n",
    "    for row in range(inner_df.shape[0]):\n",
    "        patterns.append(list_to_str(inner_df.iloc[row,1:N_COMPONENTS+1].transpose().to_list()))\n",
    "    inner_df['pattern'] = patterns\n",
    "    return inner_df # DBSCAN requires only the numeric label encoded version of the API Calls\n",
    "\n",
    "def ib_convert(input_df:pd.DataFrame):\n",
    "    print(\"Transposing IB...\")\n",
    "    input_df.transpose()\n",
    "    print(\"IB Transposed!\")\n",
    "    print(\"Removing duplicates...\")\n",
    "    print(\"Row:\", end=\" \")\n",
    "    for r in range(input_df.shape[0]):\n",
    "        row = input_df.iloc[r, 1:N_COMPONENTS+1].drop_duplicates(keep='first', inplace=False).to_list()\n",
    "        input_df.iloc[r, 1:N_COMPONENTS+1] = row + ([307]*(N_COMPONENTS-len(row)))\n",
    "        if r % N_COMPONENTS == 0:\n",
    "            print(r, end=\" \")\n",
    "    print(\"\\nDuplicates removed!\")\n",
    "    print(\"Retransposing IB (revert)...\")\n",
    "    input_df.transpose()\n",
    "    print(\"IB Retransposed!\")\n",
    "    return input_df\n",
    "\n",
    "# Remove falsely labelled malicious samples\n",
    "df = df[df['type'] != '_']\n",
    "\n",
    "# Remove specific malware types\n",
    "# removables = ['ransomware', 'miner', 'virus', 'spyware', 'hacktool', 'dropper', 'worm']\n",
    "# for r in removables:\n",
    "#     df = df[df['type'] != r]\n",
    "\n",
    "for i in range(N_COMPONENTS,100):\n",
    "    remove = f\"t_{i}\"\n",
    "    df.pop(remove)\n",
    "display(df.head())\n",
    "\n",
    "#Remove type column\n",
    "type_col = df.pop('type')\n",
    "\n",
    "#Removing hash column\n",
    "hash_col = df.pop('hash')\n",
    "\n",
    "#Re-arranging column positions\n",
    "label_col = df.pop('malware')\n",
    "df = pd.concat([label_col, df], axis=1)\n",
    "df = pd.concat([df, hash_col], axis=1) # <=== This will be retained for the benefit of model evaluation.\n",
    "df = pd.concat([df, type_col], axis=1) # <=== This will be retained for the benefit of model evaluation.\n",
    "\n",
    "#df.iloc[:, 1:N_COMPONENTS+1] = df.iloc[:, 1:N_COMPONENTS+1].apply(inverse_label, axis=1, result_type='reduce')\n",
    "#df = inject_patterns(df)\n",
    "\n",
    "mal_df = df[df['malware'] == 1]\n",
    "ben_df = df[df['malware'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Benign for Training: 969\n",
      "Bening for Test:  108\n"
     ]
    }
   ],
   "source": [
    "X = ben_df.iloc[:,1:] #Features\n",
    "y = ben_df.iloc[:,0] #Labels\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(X, y, test_size=0.10, random_state=1, shuffle=True)\n",
    "\n",
    "ben_train = pd.concat([train_labels,train_features], axis=1)\n",
    "ben_test = pd.concat([test_labels,test_features], axis=1)\n",
    "\n",
    "print(\"Benign for Training:\", ben_train['type'].value_counts().sum())\n",
    "print(\"Bening for Test: \", ben_test['type'].value_counts().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Malicious for Training: 3213\n",
      "Malicious for Testing: 36946\n"
     ]
    }
   ],
   "source": [
    "X = mal_df.iloc[:,1:] #Features\n",
    "y = mal_df.iloc[:,0] #Labels\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(X, y, test_size=0.08, random_state=1, shuffle=True)\n",
    "\n",
    "mal_test = pd.concat([train_labels,train_features], axis=1)\n",
    "mal_train = pd.concat([test_labels,test_features], axis=1)\n",
    "\n",
    "print(\"Malicious for Training:\", mal_train['type'].value_counts().sum())\n",
    "print(\"Malicious for Testing:\", mal_test['type'].value_counts().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## mal_test + ben_test\n",
    "\n",
    "To not undergo SMOTETonek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(37054, 71)\n",
      "malware\n",
      "1    36946\n",
      "0      108\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>malware</th>\n",
       "      <th>t_0</th>\n",
       "      <th>t_1</th>\n",
       "      <th>t_2</th>\n",
       "      <th>t_3</th>\n",
       "      <th>t_4</th>\n",
       "      <th>t_5</th>\n",
       "      <th>t_6</th>\n",
       "      <th>t_7</th>\n",
       "      <th>t_8</th>\n",
       "      <th>...</th>\n",
       "      <th>t_60</th>\n",
       "      <th>t_61</th>\n",
       "      <th>t_62</th>\n",
       "      <th>t_63</th>\n",
       "      <th>t_64</th>\n",
       "      <th>t_65</th>\n",
       "      <th>t_66</th>\n",
       "      <th>t_67</th>\n",
       "      <th>hash</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>82</td>\n",
       "      <td>240</td>\n",
       "      <td>117</td>\n",
       "      <td>240</td>\n",
       "      <td>117</td>\n",
       "      <td>240</td>\n",
       "      <td>117</td>\n",
       "      <td>240</td>\n",
       "      <td>117</td>\n",
       "      <td>...</td>\n",
       "      <td>141</td>\n",
       "      <td>65</td>\n",
       "      <td>260</td>\n",
       "      <td>141</td>\n",
       "      <td>65</td>\n",
       "      <td>31</td>\n",
       "      <td>261</td>\n",
       "      <td>172</td>\n",
       "      <td>ba21b9378d594b044470e1eb89e846db</td>\n",
       "      <td>trojan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>82</td>\n",
       "      <td>172</td>\n",
       "      <td>117</td>\n",
       "      <td>16</td>\n",
       "      <td>240</td>\n",
       "      <td>117</td>\n",
       "      <td>240</td>\n",
       "      <td>117</td>\n",
       "      <td>99</td>\n",
       "      <td>...</td>\n",
       "      <td>240</td>\n",
       "      <td>117</td>\n",
       "      <td>71</td>\n",
       "      <td>297</td>\n",
       "      <td>135</td>\n",
       "      <td>171</td>\n",
       "      <td>215</td>\n",
       "      <td>112</td>\n",
       "      <td>5d883b9aabe16c16c97c6e5d04b333e2</td>\n",
       "      <td>trojan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>215</td>\n",
       "      <td>117</td>\n",
       "      <td>208</td>\n",
       "      <td>117</td>\n",
       "      <td>208</td>\n",
       "      <td>117</td>\n",
       "      <td>240</td>\n",
       "      <td>117</td>\n",
       "      <td>240</td>\n",
       "      <td>...</td>\n",
       "      <td>194</td>\n",
       "      <td>117</td>\n",
       "      <td>240</td>\n",
       "      <td>117</td>\n",
       "      <td>260</td>\n",
       "      <td>141</td>\n",
       "      <td>65</td>\n",
       "      <td>260</td>\n",
       "      <td>23455429246e698971b4d9fdbe1ce2fd</td>\n",
       "      <td>trojan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>82</td>\n",
       "      <td>240</td>\n",
       "      <td>117</td>\n",
       "      <td>240</td>\n",
       "      <td>117</td>\n",
       "      <td>240</td>\n",
       "      <td>117</td>\n",
       "      <td>240</td>\n",
       "      <td>117</td>\n",
       "      <td>...</td>\n",
       "      <td>141</td>\n",
       "      <td>65</td>\n",
       "      <td>260</td>\n",
       "      <td>141</td>\n",
       "      <td>65</td>\n",
       "      <td>31</td>\n",
       "      <td>159</td>\n",
       "      <td>224</td>\n",
       "      <td>0f25b6e10708d379c09eb06bb01bb077</td>\n",
       "      <td>trojan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>82</td>\n",
       "      <td>172</td>\n",
       "      <td>117</td>\n",
       "      <td>16</td>\n",
       "      <td>81</td>\n",
       "      <td>252</td>\n",
       "      <td>81</td>\n",
       "      <td>208</td>\n",
       "      <td>257</td>\n",
       "      <td>...</td>\n",
       "      <td>303</td>\n",
       "      <td>39</td>\n",
       "      <td>303</td>\n",
       "      <td>39</td>\n",
       "      <td>303</td>\n",
       "      <td>39</td>\n",
       "      <td>303</td>\n",
       "      <td>39</td>\n",
       "      <td>d42963113be901a2fd140eb2f505fc73</td>\n",
       "      <td>trojan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 71 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   malware  t_0  t_1  t_2  t_3  t_4  t_5  t_6  t_7  t_8  ...  t_60  t_61  \\\n",
       "0        1   82  240  117  240  117  240  117  240  117  ...   141    65   \n",
       "1        1   82  172  117   16  240  117  240  117   99  ...   240   117   \n",
       "2        1  215  117  208  117  208  117  240  117  240  ...   194   117   \n",
       "3        1   82  240  117  240  117  240  117  240  117  ...   141    65   \n",
       "4        1   82  172  117   16   81  252   81  208  257  ...   303    39   \n",
       "\n",
       "   t_62  t_63  t_64  t_65  t_66  t_67                              hash  \\\n",
       "0   260   141    65    31   261   172  ba21b9378d594b044470e1eb89e846db   \n",
       "1    71   297   135   171   215   112  5d883b9aabe16c16c97c6e5d04b333e2   \n",
       "2   240   117   260   141    65   260  23455429246e698971b4d9fdbe1ce2fd   \n",
       "3   260   141    65    31   159   224  0f25b6e10708d379c09eb06bb01bb077   \n",
       "4   303    39   303    39   303    39  d42963113be901a2fd140eb2f505fc73   \n",
       "\n",
       "     type  \n",
       "0  trojan  \n",
       "1  trojan  \n",
       "2  trojan  \n",
       "3  trojan  \n",
       "4  trojan  \n",
       "\n",
       "[5 rows x 71 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>malware</th>\n",
       "      <th>t_0</th>\n",
       "      <th>t_1</th>\n",
       "      <th>t_2</th>\n",
       "      <th>t_3</th>\n",
       "      <th>t_4</th>\n",
       "      <th>t_5</th>\n",
       "      <th>t_6</th>\n",
       "      <th>t_7</th>\n",
       "      <th>t_8</th>\n",
       "      <th>...</th>\n",
       "      <th>t_60</th>\n",
       "      <th>t_61</th>\n",
       "      <th>t_62</th>\n",
       "      <th>t_63</th>\n",
       "      <th>t_64</th>\n",
       "      <th>t_65</th>\n",
       "      <th>t_66</th>\n",
       "      <th>t_67</th>\n",
       "      <th>hash</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>36946</th>\n",
       "      <td>0</td>\n",
       "      <td>82</td>\n",
       "      <td>16</td>\n",
       "      <td>208</td>\n",
       "      <td>240</td>\n",
       "      <td>117</td>\n",
       "      <td>215</td>\n",
       "      <td>274</td>\n",
       "      <td>158</td>\n",
       "      <td>215</td>\n",
       "      <td>...</td>\n",
       "      <td>172</td>\n",
       "      <td>117</td>\n",
       "      <td>172</td>\n",
       "      <td>117</td>\n",
       "      <td>172</td>\n",
       "      <td>117</td>\n",
       "      <td>172</td>\n",
       "      <td>117</td>\n",
       "      <td>59147b8b8abf9768ca96badfd91d7bb9</td>\n",
       "      <td>benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36947</th>\n",
       "      <td>0</td>\n",
       "      <td>240</td>\n",
       "      <td>117</td>\n",
       "      <td>240</td>\n",
       "      <td>117</td>\n",
       "      <td>240</td>\n",
       "      <td>117</td>\n",
       "      <td>240</td>\n",
       "      <td>117</td>\n",
       "      <td>240</td>\n",
       "      <td>...</td>\n",
       "      <td>82</td>\n",
       "      <td>245</td>\n",
       "      <td>112</td>\n",
       "      <td>240</td>\n",
       "      <td>117</td>\n",
       "      <td>50</td>\n",
       "      <td>240</td>\n",
       "      <td>117</td>\n",
       "      <td>483b022e6f2805d0cdf4e1db7d1237af</td>\n",
       "      <td>benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36948</th>\n",
       "      <td>0</td>\n",
       "      <td>240</td>\n",
       "      <td>117</td>\n",
       "      <td>240</td>\n",
       "      <td>117</td>\n",
       "      <td>240</td>\n",
       "      <td>117</td>\n",
       "      <td>240</td>\n",
       "      <td>117</td>\n",
       "      <td>240</td>\n",
       "      <td>...</td>\n",
       "      <td>240</td>\n",
       "      <td>117</td>\n",
       "      <td>240</td>\n",
       "      <td>117</td>\n",
       "      <td>228</td>\n",
       "      <td>215</td>\n",
       "      <td>274</td>\n",
       "      <td>158</td>\n",
       "      <td>76457240c1640a0812a3ef57159708b4</td>\n",
       "      <td>benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36949</th>\n",
       "      <td>0</td>\n",
       "      <td>286</td>\n",
       "      <td>110</td>\n",
       "      <td>172</td>\n",
       "      <td>240</td>\n",
       "      <td>117</td>\n",
       "      <td>240</td>\n",
       "      <td>117</td>\n",
       "      <td>240</td>\n",
       "      <td>117</td>\n",
       "      <td>...</td>\n",
       "      <td>141</td>\n",
       "      <td>65</td>\n",
       "      <td>117</td>\n",
       "      <td>9</td>\n",
       "      <td>117</td>\n",
       "      <td>260</td>\n",
       "      <td>65</td>\n",
       "      <td>141</td>\n",
       "      <td>25a904a73a9c6548c39351f3bbfac641</td>\n",
       "      <td>benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36950</th>\n",
       "      <td>0</td>\n",
       "      <td>82</td>\n",
       "      <td>16</td>\n",
       "      <td>35</td>\n",
       "      <td>240</td>\n",
       "      <td>117</td>\n",
       "      <td>86</td>\n",
       "      <td>208</td>\n",
       "      <td>86</td>\n",
       "      <td>31</td>\n",
       "      <td>...</td>\n",
       "      <td>65</td>\n",
       "      <td>141</td>\n",
       "      <td>260</td>\n",
       "      <td>65</td>\n",
       "      <td>141</td>\n",
       "      <td>65</td>\n",
       "      <td>298</td>\n",
       "      <td>297</td>\n",
       "      <td>39dfc1401b7db273933b5fb08e8394f8</td>\n",
       "      <td>benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37049</th>\n",
       "      <td>0</td>\n",
       "      <td>82</td>\n",
       "      <td>16</td>\n",
       "      <td>31</td>\n",
       "      <td>172</td>\n",
       "      <td>117</td>\n",
       "      <td>274</td>\n",
       "      <td>215</td>\n",
       "      <td>106</td>\n",
       "      <td>171</td>\n",
       "      <td>...</td>\n",
       "      <td>65</td>\n",
       "      <td>274</td>\n",
       "      <td>158</td>\n",
       "      <td>215</td>\n",
       "      <td>274</td>\n",
       "      <td>158</td>\n",
       "      <td>215</td>\n",
       "      <td>274</td>\n",
       "      <td>46691ecd93d1ba38de8eb68ab281603e</td>\n",
       "      <td>benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37050</th>\n",
       "      <td>0</td>\n",
       "      <td>82</td>\n",
       "      <td>16</td>\n",
       "      <td>172</td>\n",
       "      <td>117</td>\n",
       "      <td>194</td>\n",
       "      <td>240</td>\n",
       "      <td>117</td>\n",
       "      <td>172</td>\n",
       "      <td>117</td>\n",
       "      <td>...</td>\n",
       "      <td>252</td>\n",
       "      <td>199</td>\n",
       "      <td>252</td>\n",
       "      <td>39</td>\n",
       "      <td>199</td>\n",
       "      <td>252</td>\n",
       "      <td>199</td>\n",
       "      <td>252</td>\n",
       "      <td>824e84ac88ac9f82d772960657e094d1</td>\n",
       "      <td>benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37051</th>\n",
       "      <td>0</td>\n",
       "      <td>297</td>\n",
       "      <td>8</td>\n",
       "      <td>135</td>\n",
       "      <td>215</td>\n",
       "      <td>171</td>\n",
       "      <td>215</td>\n",
       "      <td>172</td>\n",
       "      <td>117</td>\n",
       "      <td>208</td>\n",
       "      <td>...</td>\n",
       "      <td>297</td>\n",
       "      <td>93</td>\n",
       "      <td>240</td>\n",
       "      <td>117</td>\n",
       "      <td>215</td>\n",
       "      <td>297</td>\n",
       "      <td>93</td>\n",
       "      <td>240</td>\n",
       "      <td>9b7a7f7e6df8ae601c75adb56f0ba994</td>\n",
       "      <td>benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37052</th>\n",
       "      <td>0</td>\n",
       "      <td>286</td>\n",
       "      <td>110</td>\n",
       "      <td>172</td>\n",
       "      <td>240</td>\n",
       "      <td>117</td>\n",
       "      <td>240</td>\n",
       "      <td>117</td>\n",
       "      <td>240</td>\n",
       "      <td>117</td>\n",
       "      <td>...</td>\n",
       "      <td>141</td>\n",
       "      <td>65</td>\n",
       "      <td>117</td>\n",
       "      <td>9</td>\n",
       "      <td>117</td>\n",
       "      <td>260</td>\n",
       "      <td>65</td>\n",
       "      <td>141</td>\n",
       "      <td>223d7689bbf3fbf0dc2ead33ad704689</td>\n",
       "      <td>benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37053</th>\n",
       "      <td>0</td>\n",
       "      <td>82</td>\n",
       "      <td>228</td>\n",
       "      <td>16</td>\n",
       "      <td>172</td>\n",
       "      <td>208</td>\n",
       "      <td>215</td>\n",
       "      <td>89</td>\n",
       "      <td>215</td>\n",
       "      <td>172</td>\n",
       "      <td>...</td>\n",
       "      <td>141</td>\n",
       "      <td>260</td>\n",
       "      <td>65</td>\n",
       "      <td>141</td>\n",
       "      <td>260</td>\n",
       "      <td>65</td>\n",
       "      <td>100</td>\n",
       "      <td>215</td>\n",
       "      <td>da2ed5d190fd57188abbb44e0f591f80</td>\n",
       "      <td>benign</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>108 rows × 71 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       malware  t_0  t_1  t_2  t_3  t_4  t_5  t_6  t_7  t_8  ...  t_60  t_61  \\\n",
       "36946        0   82   16  208  240  117  215  274  158  215  ...   172   117   \n",
       "36947        0  240  117  240  117  240  117  240  117  240  ...    82   245   \n",
       "36948        0  240  117  240  117  240  117  240  117  240  ...   240   117   \n",
       "36949        0  286  110  172  240  117  240  117  240  117  ...   141    65   \n",
       "36950        0   82   16   35  240  117   86  208   86   31  ...    65   141   \n",
       "...        ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   ...   ...   \n",
       "37049        0   82   16   31  172  117  274  215  106  171  ...    65   274   \n",
       "37050        0   82   16  172  117  194  240  117  172  117  ...   252   199   \n",
       "37051        0  297    8  135  215  171  215  172  117  208  ...   297    93   \n",
       "37052        0  286  110  172  240  117  240  117  240  117  ...   141    65   \n",
       "37053        0   82  228   16  172  208  215   89  215  172  ...   141   260   \n",
       "\n",
       "       t_62  t_63  t_64  t_65  t_66  t_67                              hash  \\\n",
       "36946   172   117   172   117   172   117  59147b8b8abf9768ca96badfd91d7bb9   \n",
       "36947   112   240   117    50   240   117  483b022e6f2805d0cdf4e1db7d1237af   \n",
       "36948   240   117   228   215   274   158  76457240c1640a0812a3ef57159708b4   \n",
       "36949   117     9   117   260    65   141  25a904a73a9c6548c39351f3bbfac641   \n",
       "36950   260    65   141    65   298   297  39dfc1401b7db273933b5fb08e8394f8   \n",
       "...     ...   ...   ...   ...   ...   ...                               ...   \n",
       "37049   158   215   274   158   215   274  46691ecd93d1ba38de8eb68ab281603e   \n",
       "37050   252    39   199   252   199   252  824e84ac88ac9f82d772960657e094d1   \n",
       "37051   240   117   215   297    93   240  9b7a7f7e6df8ae601c75adb56f0ba994   \n",
       "37052   117     9   117   260    65   141  223d7689bbf3fbf0dc2ead33ad704689   \n",
       "37053    65   141   260    65   100   215  da2ed5d190fd57188abbb44e0f591f80   \n",
       "\n",
       "         type  \n",
       "36946  benign  \n",
       "36947  benign  \n",
       "36948  benign  \n",
       "36949  benign  \n",
       "36950  benign  \n",
       "...       ...  \n",
       "37049  benign  \n",
       "37050  benign  \n",
       "37051  benign  \n",
       "37052  benign  \n",
       "37053  benign  \n",
       "\n",
       "[108 rows x 71 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_tb = pd.concat([mal_test, ben_test], axis=0, ignore_index=True)\n",
    "print(test_tb.shape)\n",
    "print(test_tb['malware'].value_counts())\n",
    "display(test_tb.head())\n",
    "display(test_tb[test_tb['malware']==0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## mal_train + ben_train\n",
    "\n",
    "To undergo *SMOTETomek*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4182, 71)\n",
      "malware\n",
      "1    3213\n",
      "0     969\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "train_tb = pd.concat([mal_train, ben_train], axis=0, ignore_index=True)\n",
    "print(train_tb.shape)\n",
    "print(train_tb['malware'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4486, 69)\n",
      "malware\n",
      "1    3207\n",
      "0    1279\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>malware</th>\n",
       "      <th>t_0</th>\n",
       "      <th>t_1</th>\n",
       "      <th>t_2</th>\n",
       "      <th>t_3</th>\n",
       "      <th>t_4</th>\n",
       "      <th>t_5</th>\n",
       "      <th>t_6</th>\n",
       "      <th>t_7</th>\n",
       "      <th>t_8</th>\n",
       "      <th>...</th>\n",
       "      <th>t_58</th>\n",
       "      <th>t_59</th>\n",
       "      <th>t_60</th>\n",
       "      <th>t_61</th>\n",
       "      <th>t_62</th>\n",
       "      <th>t_63</th>\n",
       "      <th>t_64</th>\n",
       "      <th>t_65</th>\n",
       "      <th>t_66</th>\n",
       "      <th>t_67</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>82</td>\n",
       "      <td>240</td>\n",
       "      <td>117</td>\n",
       "      <td>240</td>\n",
       "      <td>117</td>\n",
       "      <td>240</td>\n",
       "      <td>117</td>\n",
       "      <td>240</td>\n",
       "      <td>117</td>\n",
       "      <td>...</td>\n",
       "      <td>172</td>\n",
       "      <td>117</td>\n",
       "      <td>260</td>\n",
       "      <td>294</td>\n",
       "      <td>240</td>\n",
       "      <td>117</td>\n",
       "      <td>198</td>\n",
       "      <td>208</td>\n",
       "      <td>240</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>286</td>\n",
       "      <td>110</td>\n",
       "      <td>172</td>\n",
       "      <td>240</td>\n",
       "      <td>117</td>\n",
       "      <td>240</td>\n",
       "      <td>117</td>\n",
       "      <td>240</td>\n",
       "      <td>117</td>\n",
       "      <td>...</td>\n",
       "      <td>117</td>\n",
       "      <td>260</td>\n",
       "      <td>141</td>\n",
       "      <td>65</td>\n",
       "      <td>117</td>\n",
       "      <td>260</td>\n",
       "      <td>141</td>\n",
       "      <td>65</td>\n",
       "      <td>117</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>82</td>\n",
       "      <td>172</td>\n",
       "      <td>117</td>\n",
       "      <td>16</td>\n",
       "      <td>29</td>\n",
       "      <td>208</td>\n",
       "      <td>228</td>\n",
       "      <td>117</td>\n",
       "      <td>228</td>\n",
       "      <td>...</td>\n",
       "      <td>117</td>\n",
       "      <td>172</td>\n",
       "      <td>117</td>\n",
       "      <td>172</td>\n",
       "      <td>117</td>\n",
       "      <td>172</td>\n",
       "      <td>117</td>\n",
       "      <td>172</td>\n",
       "      <td>117</td>\n",
       "      <td>172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>82</td>\n",
       "      <td>240</td>\n",
       "      <td>117</td>\n",
       "      <td>240</td>\n",
       "      <td>117</td>\n",
       "      <td>240</td>\n",
       "      <td>117</td>\n",
       "      <td>240</td>\n",
       "      <td>117</td>\n",
       "      <td>...</td>\n",
       "      <td>159</td>\n",
       "      <td>224</td>\n",
       "      <td>82</td>\n",
       "      <td>141</td>\n",
       "      <td>65</td>\n",
       "      <td>260</td>\n",
       "      <td>141</td>\n",
       "      <td>65</td>\n",
       "      <td>260</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>82</td>\n",
       "      <td>240</td>\n",
       "      <td>117</td>\n",
       "      <td>240</td>\n",
       "      <td>117</td>\n",
       "      <td>240</td>\n",
       "      <td>117</td>\n",
       "      <td>240</td>\n",
       "      <td>117</td>\n",
       "      <td>...</td>\n",
       "      <td>65</td>\n",
       "      <td>260</td>\n",
       "      <td>141</td>\n",
       "      <td>65</td>\n",
       "      <td>260</td>\n",
       "      <td>141</td>\n",
       "      <td>65</td>\n",
       "      <td>31</td>\n",
       "      <td>261</td>\n",
       "      <td>172</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 69 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   malware  t_0  t_1  t_2  t_3  t_4  t_5  t_6  t_7  t_8  ...  t_58  t_59  \\\n",
       "0        1   82  240  117  240  117  240  117  240  117  ...   172   117   \n",
       "1        1  286  110  172  240  117  240  117  240  117  ...   117   260   \n",
       "2        1   82  172  117   16   29  208  228  117  228  ...   117   172   \n",
       "3        1   82  240  117  240  117  240  117  240  117  ...   159   224   \n",
       "4        1   82  240  117  240  117  240  117  240  117  ...    65   260   \n",
       "\n",
       "   t_60  t_61  t_62  t_63  t_64  t_65  t_66  t_67  \n",
       "0   260   294   240   117   198   208   240   117  \n",
       "1   141    65   117   260   141    65   117     9  \n",
       "2   117   172   117   172   117   172   117   172  \n",
       "3    82   141    65   260   141    65   260   141  \n",
       "4   141    65   260   141    65    31   261   172  \n",
       "\n",
       "[5 rows x 69 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>malware</th>\n",
       "      <th>t_0</th>\n",
       "      <th>t_1</th>\n",
       "      <th>t_2</th>\n",
       "      <th>t_3</th>\n",
       "      <th>t_4</th>\n",
       "      <th>t_5</th>\n",
       "      <th>t_6</th>\n",
       "      <th>t_7</th>\n",
       "      <th>t_8</th>\n",
       "      <th>...</th>\n",
       "      <th>t_58</th>\n",
       "      <th>t_59</th>\n",
       "      <th>t_60</th>\n",
       "      <th>t_61</th>\n",
       "      <th>t_62</th>\n",
       "      <th>t_63</th>\n",
       "      <th>t_64</th>\n",
       "      <th>t_65</th>\n",
       "      <th>t_66</th>\n",
       "      <th>t_67</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3207</th>\n",
       "      <td>0</td>\n",
       "      <td>286</td>\n",
       "      <td>110</td>\n",
       "      <td>172</td>\n",
       "      <td>240</td>\n",
       "      <td>117</td>\n",
       "      <td>240</td>\n",
       "      <td>117</td>\n",
       "      <td>240</td>\n",
       "      <td>117</td>\n",
       "      <td>...</td>\n",
       "      <td>117</td>\n",
       "      <td>260</td>\n",
       "      <td>141</td>\n",
       "      <td>65</td>\n",
       "      <td>117</td>\n",
       "      <td>9</td>\n",
       "      <td>117</td>\n",
       "      <td>260</td>\n",
       "      <td>65</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3208</th>\n",
       "      <td>0</td>\n",
       "      <td>82</td>\n",
       "      <td>274</td>\n",
       "      <td>158</td>\n",
       "      <td>215</td>\n",
       "      <td>86</td>\n",
       "      <td>82</td>\n",
       "      <td>37</td>\n",
       "      <td>70</td>\n",
       "      <td>37</td>\n",
       "      <td>...</td>\n",
       "      <td>262</td>\n",
       "      <td>228</td>\n",
       "      <td>275</td>\n",
       "      <td>172</td>\n",
       "      <td>240</td>\n",
       "      <td>275</td>\n",
       "      <td>172</td>\n",
       "      <td>274</td>\n",
       "      <td>158</td>\n",
       "      <td>215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3209</th>\n",
       "      <td>0</td>\n",
       "      <td>208</td>\n",
       "      <td>286</td>\n",
       "      <td>76</td>\n",
       "      <td>110</td>\n",
       "      <td>240</td>\n",
       "      <td>117</td>\n",
       "      <td>208</td>\n",
       "      <td>187</td>\n",
       "      <td>208</td>\n",
       "      <td>...</td>\n",
       "      <td>240</td>\n",
       "      <td>286</td>\n",
       "      <td>71</td>\n",
       "      <td>56</td>\n",
       "      <td>172</td>\n",
       "      <td>117</td>\n",
       "      <td>240</td>\n",
       "      <td>286</td>\n",
       "      <td>117</td>\n",
       "      <td>286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3210</th>\n",
       "      <td>0</td>\n",
       "      <td>240</td>\n",
       "      <td>117</td>\n",
       "      <td>240</td>\n",
       "      <td>117</td>\n",
       "      <td>240</td>\n",
       "      <td>117</td>\n",
       "      <td>240</td>\n",
       "      <td>117</td>\n",
       "      <td>240</td>\n",
       "      <td>...</td>\n",
       "      <td>99</td>\n",
       "      <td>198</td>\n",
       "      <td>82</td>\n",
       "      <td>208</td>\n",
       "      <td>86</td>\n",
       "      <td>260</td>\n",
       "      <td>16</td>\n",
       "      <td>112</td>\n",
       "      <td>172</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3211</th>\n",
       "      <td>0</td>\n",
       "      <td>286</td>\n",
       "      <td>110</td>\n",
       "      <td>172</td>\n",
       "      <td>240</td>\n",
       "      <td>117</td>\n",
       "      <td>240</td>\n",
       "      <td>117</td>\n",
       "      <td>240</td>\n",
       "      <td>117</td>\n",
       "      <td>...</td>\n",
       "      <td>117</td>\n",
       "      <td>260</td>\n",
       "      <td>141</td>\n",
       "      <td>65</td>\n",
       "      <td>117</td>\n",
       "      <td>9</td>\n",
       "      <td>117</td>\n",
       "      <td>260</td>\n",
       "      <td>65</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4481</th>\n",
       "      <td>0</td>\n",
       "      <td>286</td>\n",
       "      <td>110</td>\n",
       "      <td>172</td>\n",
       "      <td>240</td>\n",
       "      <td>117</td>\n",
       "      <td>240</td>\n",
       "      <td>117</td>\n",
       "      <td>240</td>\n",
       "      <td>117</td>\n",
       "      <td>...</td>\n",
       "      <td>117</td>\n",
       "      <td>260</td>\n",
       "      <td>141</td>\n",
       "      <td>65</td>\n",
       "      <td>117</td>\n",
       "      <td>9</td>\n",
       "      <td>117</td>\n",
       "      <td>260</td>\n",
       "      <td>65</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4482</th>\n",
       "      <td>0</td>\n",
       "      <td>106</td>\n",
       "      <td>183</td>\n",
       "      <td>172</td>\n",
       "      <td>117</td>\n",
       "      <td>172</td>\n",
       "      <td>117</td>\n",
       "      <td>178</td>\n",
       "      <td>141</td>\n",
       "      <td>195</td>\n",
       "      <td>...</td>\n",
       "      <td>171</td>\n",
       "      <td>131</td>\n",
       "      <td>113</td>\n",
       "      <td>145</td>\n",
       "      <td>135</td>\n",
       "      <td>98</td>\n",
       "      <td>289</td>\n",
       "      <td>226</td>\n",
       "      <td>149</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4483</th>\n",
       "      <td>0</td>\n",
       "      <td>149</td>\n",
       "      <td>91</td>\n",
       "      <td>216</td>\n",
       "      <td>157</td>\n",
       "      <td>110</td>\n",
       "      <td>157</td>\n",
       "      <td>106</td>\n",
       "      <td>189</td>\n",
       "      <td>117</td>\n",
       "      <td>...</td>\n",
       "      <td>180</td>\n",
       "      <td>114</td>\n",
       "      <td>103</td>\n",
       "      <td>188</td>\n",
       "      <td>184</td>\n",
       "      <td>188</td>\n",
       "      <td>246</td>\n",
       "      <td>269</td>\n",
       "      <td>135</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4484</th>\n",
       "      <td>0</td>\n",
       "      <td>215</td>\n",
       "      <td>274</td>\n",
       "      <td>158</td>\n",
       "      <td>215</td>\n",
       "      <td>274</td>\n",
       "      <td>158</td>\n",
       "      <td>215</td>\n",
       "      <td>172</td>\n",
       "      <td>117</td>\n",
       "      <td>...</td>\n",
       "      <td>60</td>\n",
       "      <td>81</td>\n",
       "      <td>60</td>\n",
       "      <td>81</td>\n",
       "      <td>60</td>\n",
       "      <td>81</td>\n",
       "      <td>60</td>\n",
       "      <td>81</td>\n",
       "      <td>98</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4485</th>\n",
       "      <td>0</td>\n",
       "      <td>286</td>\n",
       "      <td>110</td>\n",
       "      <td>172</td>\n",
       "      <td>240</td>\n",
       "      <td>117</td>\n",
       "      <td>240</td>\n",
       "      <td>117</td>\n",
       "      <td>240</td>\n",
       "      <td>117</td>\n",
       "      <td>...</td>\n",
       "      <td>117</td>\n",
       "      <td>260</td>\n",
       "      <td>141</td>\n",
       "      <td>65</td>\n",
       "      <td>117</td>\n",
       "      <td>9</td>\n",
       "      <td>117</td>\n",
       "      <td>260</td>\n",
       "      <td>65</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1279 rows × 69 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      malware  t_0  t_1  t_2  t_3  t_4  t_5  t_6  t_7  t_8  ...  t_58  t_59  \\\n",
       "3207        0  286  110  172  240  117  240  117  240  117  ...   117   260   \n",
       "3208        0   82  274  158  215   86   82   37   70   37  ...   262   228   \n",
       "3209        0  208  286   76  110  240  117  208  187  208  ...   240   286   \n",
       "3210        0  240  117  240  117  240  117  240  117  240  ...    99   198   \n",
       "3211        0  286  110  172  240  117  240  117  240  117  ...   117   260   \n",
       "...       ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   ...   ...   \n",
       "4481        0  286  110  172  240  117  240  117  240  117  ...   117   260   \n",
       "4482        0  106  183  172  117  172  117  178  141  195  ...   171   131   \n",
       "4483        0  149   91  216  157  110  157  106  189  117  ...   180   114   \n",
       "4484        0  215  274  158  215  274  158  215  172  117  ...    60    81   \n",
       "4485        0  286  110  172  240  117  240  117  240  117  ...   117   260   \n",
       "\n",
       "      t_60  t_61  t_62  t_63  t_64  t_65  t_66  t_67  \n",
       "3207   141    65   117     9   117   260    65   141  \n",
       "3208   275   172   240   275   172   274   158   215  \n",
       "3209    71    56   172   117   240   286   117   286  \n",
       "3210    82   208    86   260    16   112   172   117  \n",
       "3211   141    65   117     9   117   260    65   141  \n",
       "...    ...   ...   ...   ...   ...   ...   ...   ...  \n",
       "4481   141    65   117     9   117   260    65   141  \n",
       "4482   113   145   135    98   289   226   149    49  \n",
       "4483   103   188   184   188   246   269   135   110  \n",
       "4484    60    81    60    81    60    81    98    64  \n",
       "4485   141    65   117     9   117   260    65   141  \n",
       "\n",
       "[1279 rows x 69 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from imblearn.combine import SMOTETomek\n",
    "\n",
    "smt = SMOTETomek(random_state=1, n_jobs=8, sampling_strategy=0.4)\n",
    "\n",
    "X = train_tb.iloc[:,1:N_COMPONENTS+1]\n",
    "y = train_tb.iloc[:,0]\n",
    "\n",
    "X_res, y_res = smt.fit_resample(X, y)\n",
    "train_tb = pd.concat([y_res,X_res], axis=1)\n",
    "print(train_tb.shape)\n",
    "print(train_tb['malware'].value_counts())\n",
    "display(train_tb.head())\n",
    "display(train_tb[train_tb['malware']==0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating IB versions of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transposing IB...\n",
      "IB Transposed!\n",
      "Removing duplicates...\n",
      "Row: 0 68 136 204 272 340 408 476 544 612 680 748 816 884 952 1020 1088 1156 1224 1292 1360 1428 1496 1564 1632 1700 1768 1836 1904 1972 2040 2108 2176 2244 2312 2380 2448 2516 2584 2652 2720 2788 2856 2924 2992 3060 3128 3196 3264 3332 3400 3468 3536 3604 3672 3740 3808 3876 3944 4012 4080 4148 4216 4284 4352 4420 \n",
      "Duplicates removed!\n",
      "Retransposing IB (revert)...\n",
      "IB Retransposed!\n",
      "\n",
      "\n",
      "Transposing IB...\n",
      "IB Transposed!\n",
      "Removing duplicates...\n",
      "Row: 0 68 136 204 272 340 408 476 544 612 680 748 816 884 952 1020 1088 1156 1224 1292 1360 1428 1496 1564 1632 1700 1768 1836 1904 1972 2040 2108 2176 2244 2312 2380 2448 2516 2584 2652 2720 2788 2856 2924 2992 3060 3128 3196 3264 3332 3400 3468 3536 3604 3672 3740 3808 3876 3944 4012 4080 4148 4216 4284 4352 4420 4488 4556 4624 4692 4760 4828 4896 4964 5032 5100 5168 5236 5304 5372 5440 5508 5576 5644 5712 5780 5848 5916 5984 6052 6120 6188 6256 6324 6392 6460 6528 6596 6664 6732 6800 6868 6936 7004 7072 7140 7208 7276 7344 7412 7480 7548 7616 7684 7752 7820 7888 7956 8024 8092 8160 8228 8296 8364 8432 8500 8568 8636 8704 8772 8840 8908 8976 9044 9112 9180 9248 9316 9384 9452 9520 9588 9656 9724 9792 9860 9928 9996 10064 10132 10200 10268 10336 10404 10472 10540 10608 10676 10744 10812 10880 10948 11016 11084 11152 11220 11288 11356 11424 11492 11560 11628 11696 11764 11832 11900 11968 12036 12104 12172 12240 12308 12376 12444 12512 12580 12648 12716 12784 12852 12920 12988 13056 13124 13192 13260 13328 13396 13464 13532 13600 13668 13736 13804 13872 13940 14008 14076 14144 14212 14280 14348 14416 14484 14552 14620 14688 14756 14824 14892 14960 15028 15096 15164 15232 15300 15368 15436 15504 15572 15640 15708 15776 15844 15912 15980 16048 16116 16184 16252 16320 16388 16456 16524 16592 16660 16728 16796 16864 16932 17000 17068 17136 17204 17272 17340 17408 17476 17544 17612 17680 17748 17816 17884 17952 18020 18088 18156 18224 18292 18360 18428 18496 18564 18632 18700 18768 18836 18904 18972 19040 19108 19176 19244 19312 19380 19448 19516 19584 19652 19720 19788 19856 19924 19992 20060 20128 20196 20264 20332 20400 20468 20536 20604 20672 20740 20808 20876 20944 21012 21080 21148 21216 21284 21352 21420 21488 21556 21624 21692 21760 21828 21896 21964 22032 22100 22168 22236 22304 22372 22440 22508 22576 22644 22712 22780 22848 22916 22984 23052 23120 23188 23256 23324 23392 23460 23528 23596 23664 23732 23800 23868 23936 24004 24072 24140 24208 24276 24344 24412 24480 24548 24616 24684 24752 24820 24888 24956 25024 25092 25160 25228 25296 25364 25432 25500 25568 25636 25704 25772 25840 25908 25976 26044 26112 26180 26248 26316 26384 26452 26520 26588 26656 26724 26792 26860 26928 26996 27064 27132 27200 27268 27336 27404 27472 27540 27608 27676 27744 27812 27880 27948 28016 28084 28152 28220 28288 28356 28424 28492 28560 28628 28696 28764 28832 28900 28968 29036 29104 29172 29240 29308 29376 29444 29512 29580 29648 29716 29784 29852 29920 29988 30056 30124 30192 30260 30328 30396 30464 30532 30600 30668 30736 30804 30872 30940 31008 31076 31144 31212 31280 31348 31416 31484 31552 31620 31688 31756 31824 31892 31960 32028 32096 32164 32232 32300 32368 32436 32504 32572 32640 32708 32776 32844 32912 32980 33048 33116 33184 33252 33320 33388 33456 33524 33592 33660 33728 33796 33864 33932 34000 34068 34136 34204 34272 34340 34408 34476 34544 34612 34680 34748 34816 34884 34952 35020 35088 35156 35224 35292 35360 35428 35496 35564 35632 35700 35768 35836 35904 35972 36040 36108 36176 36244 36312 36380 36448 36516 36584 36652 36720 36788 36856 36924 36992 \n",
      "Duplicates removed!\n",
      "Retransposing IB (revert)...\n",
      "IB Retransposed!\n"
     ]
    }
   ],
   "source": [
    "train_ib = train_tb.copy(deep=True)\n",
    "test_ib = test_tb.copy(deep=True)\n",
    "\n",
    "train_ib = ib_convert(train_ib).copy(deep=True)\n",
    "print(\"\\n\")\n",
    "test_ib = ib_convert(test_ib).copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_ib.iloc[:,1:N_COMPONENTS+1] = train_ib.iloc[:,1:N_COMPONENTS+1].astype('str')\n",
    "# train_ib.replace(\"nan\", \"NaN\", inplace=True)\n",
    "# test_ib.iloc[:,1:N_COMPONENTS+1] = test_ib.iloc[:,1:N_COMPONENTS+1].astype('str')\n",
    "# test_ib.replace(\"nan\", \"NaN\", inplace=True)\n",
    "# display(train_ib.head())\n",
    "# display(test_ib.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting results to usable for models\n",
    "\n",
    "Encoded APIs to Unencoded/String APIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# train_tb_enc = train_tb.copy(deep=True)\n",
    "# test_tb_enc = test_tb.copy(deep=True)\n",
    "# train_ib_enc = train_ib.copy(deep=True)\n",
    "# test_ib_enc = test_ib.copy(deep=True)\n",
    "\n",
    "# train_tb_enc.iloc[:, 1:N_COMPONENTS+1] = train_tb.iloc[:, 1:N_COMPONENTS+1].apply(inverse_label, axis=1, result_type='reduce')\n",
    "# test_tb_enc.iloc[:, 1:N_COMPONENTS+1] = test_tb.iloc[:, 1:N_COMPONENTS+1].apply(inverse_label, axis=1, result_type='reduce')\n",
    "# train_ib_enc.iloc[:, 1:N_COMPONENTS+1] = train_ib.iloc[:, 1:N_COMPONENTS+1].apply(inverse_label, axis=1, result_type='reduce')\n",
    "# test_ib_enc.iloc[:, 1:N_COMPONENTS+1] = test_ib.iloc[:, 1:N_COMPONENTS+1].apply(inverse_label, axis=1, result_type='reduce')\n",
    "\n",
    "# display(train_tb_enc.head())\n",
    "# display(test_tb_enc.head())\n",
    "# display(train_ib_enc.head())\n",
    "# display(test_ib_enc.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying it out on LightGBM, CatBoost, and SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_indexes():\n",
    "    indexes = []\n",
    "    for i in range(N_COMPONENTS):\n",
    "        indexes.append(f\"t_{i}\")\n",
    "    return indexes\n",
    "\n",
    "def train_test(train, test, model, model_str:str):\n",
    "    X = train.iloc[:,1:N_COMPONENTS+1]\n",
    "    y = train.iloc[:,0]\n",
    "    X_test = test.iloc[:,1:N_COMPONENTS+1]\n",
    "    y_test = test.iloc[:,0]\n",
    "    print(f\"Model: {model_str}\")\n",
    "    #MODEL ROBUSTNESS\n",
    "    model.fit(X,y)\n",
    "    y_pred = model.predict(X_test)\n",
    "    #print(\"\\nModel, Fold, Accuracy, Precision, F1-Score, Recall, ROC-AUC\")\n",
    "    #print(f\"{model_str}, {'T'}, {metrics.accuracy_score(y_test, y_pred):.4f}, {metrics.average_precision_score(y_test, y_pred):.4f}, {metrics.f1_score(y_test, y_pred):.4f}, {metrics.recall_score(y_test, y_pred):.4f}, {metrics.roc_auc_score(y_test, y_pred):.4f}\")\n",
    "    print(f\"Fold: T\")\n",
    "    print(classification_report(y_test, y_pred, digits=4))\n",
    "    print(f\"ROC-AUC: {metrics.roc_auc_score(y_test, y_pred):.4f}\")\n",
    "    #STRATIFIED K-FOLDS\n",
    "    skf = StratifiedKFold(n_splits=5, random_state=1, shuffle=True)\n",
    "    ctr = 0\n",
    "    for train_idx, test_idx in skf.split(train.iloc[:,1:N_COMPONENTS+1], train.iloc[:,0]):\n",
    "        X_train = train.iloc[train_idx, 1:N_COMPONENTS+1]\n",
    "        y_train = train.iloc[train_idx, 0]\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(train.iloc[test_idx, 1:N_COMPONENTS+1])\n",
    "        y_test = train.iloc[test_idx, 0]\n",
    "        #print(f\"{model_str}, {ctr}, {metrics.accuracy_score(y_test, y_pred):.4f}, {metrics.average_precision_score(y_test, y_pred):.4f}, {metrics.f1_score(y_test, y_pred):.4f}, {metrics.recall_score(y_test, y_pred):.4f}, {metrics.roc_auc_score(y_test, y_pred):.4f}\")\n",
    "        print(f\"Fold: {ctr}\")\n",
    "        print(classification_report(y_test, y_pred, digits=4))\n",
    "        ctr += 1\n",
    "    print('-------------------------------------------------------')\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: LGBM\n",
      "Fold: T\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0352    0.8241    0.0675       108\n",
      "           1     0.9994    0.9339    0.9656     36946\n",
      "\n",
      "    accuracy                         0.9336     37054\n",
      "   macro avg     0.5173    0.8790    0.5165     37054\n",
      "weighted avg     0.9966    0.9336    0.9630     37054\n",
      "\n",
      "ROC-AUC: 0.8790\n",
      "Fold: 0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8015    0.8516    0.8258       256\n",
      "           1     0.9393    0.9159    0.9274       642\n",
      "\n",
      "    accuracy                         0.8976       898\n",
      "   macro avg     0.8704    0.8837    0.8766       898\n",
      "weighted avg     0.9000    0.8976    0.8985       898\n",
      "\n",
      "Fold: 1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7924    0.8980    0.8419       255\n",
      "           1     0.9572    0.9065    0.9312       642\n",
      "\n",
      "    accuracy                         0.9041       897\n",
      "   macro avg     0.8748    0.9023    0.8866       897\n",
      "weighted avg     0.9104    0.9041    0.9058       897\n",
      "\n",
      "Fold: 2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8105    0.9023    0.8540       256\n",
      "           1     0.9592    0.9158    0.9370       641\n",
      "\n",
      "    accuracy                         0.9119       897\n",
      "   macro avg     0.8848    0.9091    0.8955       897\n",
      "weighted avg     0.9167    0.9119    0.9133       897\n",
      "\n",
      "Fold: 3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8037    0.8477    0.8251       256\n",
      "           1     0.9378    0.9173    0.9274       641\n",
      "\n",
      "    accuracy                         0.8974       897\n",
      "   macro avg     0.8708    0.8825    0.8763       897\n",
      "weighted avg     0.8995    0.8974    0.8982       897\n",
      "\n",
      "Fold: 4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8577    0.8477    0.8527       256\n",
      "           1     0.9394    0.9438    0.9416       641\n",
      "\n",
      "    accuracy                         0.9164       897\n",
      "   macro avg     0.8986    0.8957    0.8971       897\n",
      "weighted avg     0.9161    0.9164    0.9162       897\n",
      "\n",
      "-------------------------------------------------------\n",
      "\n",
      "Model: CATB\n",
      "Fold: T\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0380    0.8241    0.0726       108\n",
      "           1     0.9995    0.9390    0.9683     36946\n",
      "\n",
      "    accuracy                         0.9386     37054\n",
      "   macro avg     0.5187    0.8815    0.5204     37054\n",
      "weighted avg     0.9967    0.9386    0.9657     37054\n",
      "\n",
      "ROC-AUC: 0.8815\n",
      "Fold: 0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8115    0.7734    0.7920       256\n",
      "           1     0.9113    0.9283    0.9198       642\n",
      "\n",
      "    accuracy                         0.8842       898\n",
      "   macro avg     0.8614    0.8509    0.8559       898\n",
      "weighted avg     0.8829    0.8842    0.8833       898\n",
      "\n",
      "Fold: 1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7757    0.8275    0.8008       255\n",
      "           1     0.9296    0.9050    0.9171       642\n",
      "\n",
      "    accuracy                         0.8829       897\n",
      "   macro avg     0.8527    0.8662    0.8589       897\n",
      "weighted avg     0.8859    0.8829    0.8840       897\n",
      "\n",
      "Fold: 2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8111    0.8555    0.8327       256\n",
      "           1     0.9410    0.9204    0.9306       641\n",
      "\n",
      "    accuracy                         0.9019       897\n",
      "   macro avg     0.8760    0.8880    0.8816       897\n",
      "weighted avg     0.9039    0.9019    0.9027       897\n",
      "\n",
      "Fold: 3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8145    0.7891    0.8016       256\n",
      "           1     0.9168    0.9282    0.9225       641\n",
      "\n",
      "    accuracy                         0.8885       897\n",
      "   macro avg     0.8657    0.8586    0.8620       897\n",
      "weighted avg     0.8876    0.8885    0.8880       897\n",
      "\n",
      "Fold: 4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8475    0.7812    0.8130       256\n",
      "           1     0.9153    0.9438    0.9293       641\n",
      "\n",
      "    accuracy                         0.8974       897\n",
      "   macro avg     0.8814    0.8625    0.8712       897\n",
      "weighted avg     0.8959    0.8974    0.8961       897\n",
      "\n",
      "-------------------------------------------------------\n",
      "\n",
      "Model: SVM\n",
      "Fold: T\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0296    0.7963    0.0570       108\n",
      "           1     0.9994    0.9236    0.9600     36946\n",
      "\n",
      "    accuracy                         0.9232     37054\n",
      "   macro avg     0.5145    0.8599    0.5085     37054\n",
      "weighted avg     0.9965    0.9232    0.9573     37054\n",
      "\n",
      "ROC-AUC: 0.8599\n",
      "Fold: 0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7744    0.8047    0.7893       256\n",
      "           1     0.9209    0.9065    0.9137       642\n",
      "\n",
      "    accuracy                         0.8775       898\n",
      "   macro avg     0.8477    0.8556    0.8515       898\n",
      "weighted avg     0.8791    0.8775    0.8782       898\n",
      "\n",
      "Fold: 1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7735    0.8706    0.8192       255\n",
      "           1     0.9459    0.8988    0.9217       642\n",
      "\n",
      "    accuracy                         0.8907       897\n",
      "   macro avg     0.8597    0.8847    0.8705       897\n",
      "weighted avg     0.8969    0.8907    0.8926       897\n",
      "\n",
      "Fold: 2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8030    0.8438    0.8229       256\n",
      "           1     0.9363    0.9173    0.9267       641\n",
      "\n",
      "    accuracy                         0.8963       897\n",
      "   macro avg     0.8696    0.8805    0.8748       897\n",
      "weighted avg     0.8983    0.8963    0.8971       897\n",
      "\n",
      "Fold: 3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7857    0.8164    0.8008       256\n",
      "           1     0.9255    0.9111    0.9182       641\n",
      "\n",
      "    accuracy                         0.8841       897\n",
      "   macro avg     0.8556    0.8637    0.8595       897\n",
      "weighted avg     0.8856    0.8841    0.8847       897\n",
      "\n",
      "Fold: 4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8275    0.8242    0.8258       256\n",
      "           1     0.9299    0.9314    0.9306       641\n",
      "\n",
      "    accuracy                         0.9008       897\n",
      "   macro avg     0.8787    0.8778    0.8782       897\n",
      "weighted avg     0.9007    0.9008    0.9007       897\n",
      "\n",
      "-------------------------------------------------------\n",
      "\n",
      "Model: MLPC\n",
      "Fold: T\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0234    0.7315    0.0454       108\n",
      "           1     0.9991    0.9109    0.9530     36946\n",
      "\n",
      "    accuracy                         0.9104     37054\n",
      "   macro avg     0.5113    0.8212    0.4992     37054\n",
      "weighted avg     0.9963    0.9104    0.9503     37054\n",
      "\n",
      "ROC-AUC: 0.8212\n",
      "Fold: 0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6854    0.8594    0.7626       256\n",
      "           1     0.9376    0.8427    0.8876       642\n",
      "\n",
      "    accuracy                         0.8474       898\n",
      "   macro avg     0.8115    0.8510    0.8251       898\n",
      "weighted avg     0.8657    0.8474    0.8520       898\n",
      "\n",
      "Fold: 1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6997    0.8863    0.7820       255\n",
      "           1     0.9495    0.8489    0.8964       642\n",
      "\n",
      "    accuracy                         0.8595       897\n",
      "   macro avg     0.8246    0.8676    0.8392       897\n",
      "weighted avg     0.8785    0.8595    0.8639       897\n",
      "\n",
      "Fold: 2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7594    0.7891    0.7739       256\n",
      "           1     0.9144    0.9002    0.9072       641\n",
      "\n",
      "    accuracy                         0.8685       897\n",
      "   macro avg     0.8369    0.8446    0.8406       897\n",
      "weighted avg     0.8702    0.8685    0.8692       897\n",
      "\n",
      "Fold: 3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7925    0.4922    0.6072       256\n",
      "           1     0.8238    0.9485    0.8818       641\n",
      "\n",
      "    accuracy                         0.8183       897\n",
      "   macro avg     0.8082    0.7204    0.7445       897\n",
      "weighted avg     0.8149    0.8183    0.8034       897\n",
      "\n",
      "Fold: 4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7413    0.8281    0.7823       256\n",
      "           1     0.9280    0.8846    0.9058       641\n",
      "\n",
      "    accuracy                         0.8685       897\n",
      "   macro avg     0.8346    0.8563    0.8440       897\n",
      "weighted avg     0.8747    0.8685    0.8705       897\n",
      "\n",
      "-------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_test(train_tb, test_tb, lgbm.LGBMClassifier(random_state=1, n_jobs=0, verbose=0), \"LGBM\")\n",
    "train_test(train_tb, test_tb, catb.CatBoostClassifier(random_state=1, thread_count=-1, verbose=0, cat_features=get_indexes(), \n",
    "                                                    nan_mode='Min', custom_metric=['Logloss', 'AUC', 'Precision'], one_hot_max_size=256), \"CATB\")\n",
    "train_test(train_tb, test_tb, svc.SVC(random_state=1, verbose=0), \"SVM\")\n",
    "train_test(train_tb, test_tb, mlpc.MLPClassifier(random_state=1, verbose=0), \"MLPC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: LGBM\n",
      "Fold: T\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0328    0.8333    0.0631       108\n",
      "           1     0.9995    0.9282    0.9625     36946\n",
      "\n",
      "    accuracy                         0.9279     37054\n",
      "   macro avg     0.5161    0.8808    0.5128     37054\n",
      "weighted avg     0.9967    0.9279    0.9599     37054\n",
      "\n",
      "ROC-AUC: 0.8808\n",
      "Fold: 0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7832    0.8750    0.8266       256\n",
      "           1     0.9477    0.9034    0.9250       642\n",
      "\n",
      "    accuracy                         0.8953       898\n",
      "   macro avg     0.8655    0.8892    0.8758       898\n",
      "weighted avg     0.9008    0.8953    0.8970       898\n",
      "\n",
      "Fold: 1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7951    0.8980    0.8435       255\n",
      "           1     0.9573    0.9081    0.9321       642\n",
      "\n",
      "    accuracy                         0.9052       897\n",
      "   macro avg     0.8762    0.9031    0.8878       897\n",
      "weighted avg     0.9112    0.9052    0.9069       897\n",
      "\n",
      "Fold: 2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8036    0.8789    0.8396       256\n",
      "           1     0.9498    0.9142    0.9316       641\n",
      "\n",
      "    accuracy                         0.9041       897\n",
      "   macro avg     0.8767    0.8966    0.8856       897\n",
      "weighted avg     0.9080    0.9041    0.9054       897\n",
      "\n",
      "Fold: 3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8104    0.8516    0.8305       256\n",
      "           1     0.9395    0.9204    0.9299       641\n",
      "\n",
      "    accuracy                         0.9008       897\n",
      "   macro avg     0.8749    0.8860    0.8802       897\n",
      "weighted avg     0.9027    0.9008    0.9015       897\n",
      "\n",
      "Fold: 4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8429    0.8594    0.8511       256\n",
      "           1     0.9434    0.9360    0.9397       641\n",
      "\n",
      "    accuracy                         0.9142       897\n",
      "   macro avg     0.8932    0.8977    0.8954       897\n",
      "weighted avg     0.9147    0.9142    0.9144       897\n",
      "\n",
      "-------------------------------------------------------\n",
      "\n",
      "Model: CATB\n",
      "Fold: T\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0380    0.8333    0.0727       108\n",
      "           1     0.9995    0.9383    0.9679     36946\n",
      "\n",
      "    accuracy                         0.9380     37054\n",
      "   macro avg     0.5187    0.8858    0.5203     37054\n",
      "weighted avg     0.9967    0.9380    0.9653     37054\n",
      "\n",
      "ROC-AUC: 0.8858\n",
      "Fold: 0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8189    0.8125    0.8157       256\n",
      "           1     0.9255    0.9283    0.9269       642\n",
      "\n",
      "    accuracy                         0.8953       898\n",
      "   macro avg     0.8722    0.8704    0.8713       898\n",
      "weighted avg     0.8951    0.8953    0.8952       898\n",
      "\n",
      "Fold: 1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8213    0.8471    0.8340       255\n",
      "           1     0.9385    0.9268    0.9326       642\n",
      "\n",
      "    accuracy                         0.9041       897\n",
      "   macro avg     0.8799    0.8869    0.8833       897\n",
      "weighted avg     0.9052    0.9041    0.9046       897\n",
      "\n",
      "Fold: 2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8182    0.8438    0.8308       256\n",
      "           1     0.9368    0.9251    0.9309       641\n",
      "\n",
      "    accuracy                         0.9019       897\n",
      "   macro avg     0.8775    0.8844    0.8808       897\n",
      "weighted avg     0.9030    0.9019    0.9023       897\n",
      "\n",
      "Fold: 3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8056    0.7930    0.7992       256\n",
      "           1     0.9178    0.9236    0.9207       641\n",
      "\n",
      "    accuracy                         0.8863       897\n",
      "   macro avg     0.8617    0.8583    0.8599       897\n",
      "weighted avg     0.8858    0.8863    0.8860       897\n",
      "\n",
      "Fold: 4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8631    0.8125    0.8370       256\n",
      "           1     0.9268    0.9485    0.9375       641\n",
      "\n",
      "    accuracy                         0.9097       897\n",
      "   macro avg     0.8949    0.8805    0.8873       897\n",
      "weighted avg     0.9086    0.9097    0.9089       897\n",
      "\n",
      "-------------------------------------------------------\n",
      "\n",
      "Model: SVM\n",
      "Fold: T\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0260    0.7222    0.0502       108\n",
      "           1     0.9991    0.9210    0.9585     36946\n",
      "\n",
      "    accuracy                         0.9204     37054\n",
      "   macro avg     0.5126    0.8216    0.5044     37054\n",
      "weighted avg     0.9963    0.9204    0.9558     37054\n",
      "\n",
      "ROC-AUC: 0.8216\n",
      "Fold: 0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7550    0.7344    0.7446       256\n",
      "           1     0.8952    0.9050    0.9001       642\n",
      "\n",
      "    accuracy                         0.8563       898\n",
      "   macro avg     0.8251    0.8197    0.8223       898\n",
      "weighted avg     0.8553    0.8563    0.8557       898\n",
      "\n",
      "Fold: 1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7747    0.7686    0.7717       255\n",
      "           1     0.9084    0.9112    0.9098       642\n",
      "\n",
      "    accuracy                         0.8707       897\n",
      "   macro avg     0.8415    0.8399    0.8407       897\n",
      "weighted avg     0.8704    0.8707    0.8705       897\n",
      "\n",
      "Fold: 2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7632    0.7930    0.7778       256\n",
      "           1     0.9160    0.9017    0.9088       641\n",
      "\n",
      "    accuracy                         0.8707       897\n",
      "   macro avg     0.8396    0.8473    0.8433       897\n",
      "weighted avg     0.8724    0.8707    0.8714       897\n",
      "\n",
      "Fold: 3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7645    0.7734    0.7689       256\n",
      "           1     0.9091    0.9048    0.9070       641\n",
      "\n",
      "    accuracy                         0.8673       897\n",
      "   macro avg     0.8368    0.8391    0.8379       897\n",
      "weighted avg     0.8678    0.8673    0.8676       897\n",
      "\n",
      "Fold: 4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8190    0.7422    0.7787       256\n",
      "           1     0.9008    0.9345    0.9173       641\n",
      "\n",
      "    accuracy                         0.8796       897\n",
      "   macro avg     0.8599    0.8383    0.8480       897\n",
      "weighted avg     0.8774    0.8796    0.8777       897\n",
      "\n",
      "-------------------------------------------------------\n",
      "\n",
      "Model: MLPC\n",
      "Fold: T\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0320    0.1759    0.0541       108\n",
      "           1     0.9976    0.9844    0.9910     36946\n",
      "\n",
      "    accuracy                         0.9821     37054\n",
      "   macro avg     0.5148    0.5802    0.5225     37054\n",
      "weighted avg     0.9947    0.9821    0.9882     37054\n",
      "\n",
      "ROC-AUC: 0.5802\n",
      "Fold: 0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5968    0.8789    0.7109       256\n",
      "           1     0.9405    0.7632    0.8426       642\n",
      "\n",
      "    accuracy                         0.7962       898\n",
      "   macro avg     0.7687    0.8211    0.7768       898\n",
      "weighted avg     0.8425    0.7962    0.8051       898\n",
      "\n",
      "Fold: 1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9412    0.3137    0.4706       255\n",
      "           1     0.7845    0.9922    0.8762       642\n",
      "\n",
      "    accuracy                         0.7993       897\n",
      "   macro avg     0.8628    0.6530    0.6734       897\n",
      "weighted avg     0.8290    0.7993    0.7609       897\n",
      "\n",
      "Fold: 2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8485    0.2188    0.3478       256\n",
      "           1     0.7593    0.9844    0.8573       641\n",
      "\n",
      "    accuracy                         0.7659       897\n",
      "   macro avg     0.8039    0.6016    0.6026       897\n",
      "weighted avg     0.7848    0.7659    0.7119       897\n",
      "\n",
      "Fold: 3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6970    0.8086    0.7486       256\n",
      "           1     0.9183    0.8596    0.8880       641\n",
      "\n",
      "    accuracy                         0.8450       897\n",
      "   macro avg     0.8077    0.8341    0.8183       897\n",
      "weighted avg     0.8552    0.8450    0.8482       897\n",
      "\n",
      "Fold: 4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6243    0.8633    0.7246       256\n",
      "           1     0.9355    0.7925    0.8581       641\n",
      "\n",
      "    accuracy                         0.8127       897\n",
      "   macro avg     0.7799    0.8279    0.7913       897\n",
      "weighted avg     0.8467    0.8127    0.8200       897\n",
      "\n",
      "-------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_test(train_ib, test_ib, lgbm.LGBMClassifier(random_state=1, n_jobs=0,verbose=0), \"LGBM\")\n",
    "train_test(train_ib, test_ib, catb.CatBoostClassifier(random_state=1, thread_count=-1, verbose=0, cat_features=get_indexes(), \n",
    "                                                    nan_mode='Min', custom_metric=['Logloss', 'AUC', 'Precision'], one_hot_max_size=256), \"CATB\")\n",
    "train_test(train_ib, test_ib, svc.SVC(random_state=1,verbose=0), \"SVM\")\n",
    "train_test(train_ib, test_ib, mlpc.MLPClassifier(random_state=1,verbose=0), \"MLPC\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
